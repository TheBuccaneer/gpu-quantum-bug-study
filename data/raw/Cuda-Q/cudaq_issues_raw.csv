<,IssueID,URL,Title,Status,CreatedAt,BugType ,StackLayer,,CTClass,subtype,reason Bug,reason Stack,reason Class
NVIDIA/cuda-quantum,3433,https://github.com/NVIDIA/cuda-quantum/issues/3433,Can not pip install cudaq on Ubuntu 22.04,open,2025-09-10T22:11:20Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment ,B ,B ,B1,The PyPI cudaq source distributions are published with broken package metadata where the project name is reported as unknown ,The problem lives in the build pipeline for Python (pyproject),A packaging linter or CI step that validates the built Wheel metadata could detect this mismatch deterministically before Publishing. Fits  B1
NVIDIA/cuda-quantum,2937,https://github.com/NVIDIA/cuda-quantum/issues/2937,Wrong simulation result with the tensornet/tensornet-mps target,closed,2025-05-21T06:22:52Z,Performance-/Numerik-Bug ,Backend-Library ,C,C,,"For this specific highly structured 20-qubit circuit, the tensornet and tensornet-mps targets return a sample distribution that only contains 8 bitstrings instead of the 16 bitstrings ",The issue is confined to the tensor-network simulation backend. It is located in the Cuda-Q backend library. ,It is a numerical or algorithmic error in the backend logic. Therefore it cannot be detected at compile time.
NVIDIA/cuda-quantum,2641,https://github.com/NVIDIA/cuda-quantum/issues/2641,Testing regression introduced with python/tests/kernel/test_explicit_measurements.py,closed,2025-02-20T18:10:53Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment,B ,B ,B1,A change introduced in PR #2567 broke the Python test python/tests/kernel/test_explicit_measurements.py,The problem is the test harness and its target discovery logic that are incorrect for partial builds. Cuda-Q Kernel seem fine,"This is a configuration problem, which could be solved with a configuration check. Skipping the config could help. Fits B1 "
NVIDIA/cuda-quantum,2628,https://github.com/NVIDIA/cuda-quantum/issues/2628,using cudaq.State and mqpu backend to run two independent circuit gives error,open,2025-02-17T20:35:00Z,Backend-/Framework-Integrations-Bug,Runtime-/Framework-Runtime ,C,C,,"When the user prepares two cudaq.State objects from CuPy data and runs the same kernel on the nvidia target with option=""mqpu"" using sample_async on qpu_id=0 and qpu_id=1, the program aborts with ubackend::RuntimeError: cudaErrorIllegalAddress",The issue is rooted in the CUDA-Q backend. This points to abug in backend library. ,Illegal device address at runtime is low level memory management. 
NVIDIA/cuda-quantum,2627,https://github.com/NVIDIA/cuda-quantum/issues/2627,List of list in kernel argument gives error,open,2025-02-17T16:38:51Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,A,A,,"When the kernel is declared with a nested Python type annotation and called with a list-of-lists argument, CUDA-Q fails at runtime with RuntimeError","The problem resides in the high-level Python language binding and its type-mapping layer. Kernel call uses  Python syntax, but Cuda-Q does not support this.",We could use a expressive static type checker for rejecting unsupported nested container types. This could be done at compile time.
NVIDIA/cuda-quantum,2625,https://github.com/NVIDIA/cuda-quantum/issues/2625,[Python][MLIR?] Loop miscompilation,closed,2025-02-17T15:45:17Z,API-/Usage-/Logic-Bug (High-Level) ,Backend-Library ,B ,B ,B2,Compiling the bar kernel crashes with an LLVM/MLIR assertion. ,The problem is in the Cuda-Q compiler / MLIR backend. ,"A robust IR verifier running after control flow transformation could detected that mlir::value with no attached result is being treated as an OpResult. This requieres IR level validation. Not simple compile time check, so B2"
NVIDIA/cuda-quantum,2608,https://github.com/NVIDIA/cuda-quantum/issues/2608,The bridge failing to deal with captured globals.,open,2025-02-11T12:18:59Z,API-/Usage-/Logic-Bug (High-Level),Framework-Integration,B ,B ,B2,The Python Q bridge records it in the symbol table as !cc.ptr<f64> instead of plain f64,The problem lies in the framework integration layer. ,Could possibly be resolved with data flow manager with capturied symbols to verify statically the globals used as scalar parameters. Fits B2 
NVIDIA/cuda-quantum,2600,https://github.com/NVIDIA/cuda-quantum/issues/2600,Return list[complex] fails when returning list[float],closed,2025-02-07T15:17:46Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,A,A,,error: type of return operand 0 ('!cc.stdvec<f64>') doesn't match function result type ('!cc.stdvec<complex<f64>>') in function @__nvqpp__mlirgen__myop,"Usere code is syntactivally valid, but the bridge does not reconcile the list annoation with a float-valued list literal.", more advanced static type checker could be used for the front-end. It could detect return expression has ceratin type. Match this class A
NVIDIA/cuda-quantum,2593,https://github.com/NVIDIA/cuda-quantum/issues/2593,cannot use @cudaq.kernel in the interpreter: OSError: could not get source code,open,2025-02-06T16:42:27Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,"When the user types the @cudaq.kernel example from the official VQE tutorial directly into an interactive Python interpreter, the decorator fails",The failure occurs entirely in the high-level Python API. No backend simulation or procedure is involved.,Bug seems to be limited at at specific interpreter environment and is bound to Python semantics. How to rule out this at compile time? Class C
NVIDIA/cuda-quantum,2575,https://github.com/NVIDIA/cuda-quantum/issues/2575,custom gate register_operation doesn't seem to work if it is invoked in one kernel which is nested in another.,open,2025-02-02T19:37:34Z,API-/Usage-/Logic-Bug (High-Level) ,Framework-Integration ,C,C,,"A custom matrix gate registered via cudaq.register_operation(""my_gate"", my_matrix) can be called in a kernel, but calling it through a nested kernel is ignored",It seems like the problem is in the Python Framework integration that connects custom registered operations into kernel call graphs.,"Hard to impossible to validate, because detecting requieres reasoning which is not simply checked at compile time. Fits C "
NVIDIA/cuda-quantum,2560,https://github.com/NVIDIA/cuda-quantum/issues/2560,Input argument to a kernel throws an error,open,2025-01-30T16:21:31Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,A,A,,"A kernel with def kernel(list) cannot be called with a = [(1,2)]. The Python bridge raises an error while trying to interpret the list. ",Parses annotations and builds python to Q type mapping. Seems to be high level Python API to framework mapping problem.,A stronger static checker for the Python fron-end could detect that list of touples is an unsupported operation. Fits A
NVIDIA/cuda-quantum,2550,https://github.com/NVIDIA/cuda-quantum/issues/2550,[Python] Noise channels don't respect single/double precision setting of the target,closed,2025-01-28T00:33:22Z,Performance-/Numerik-Bug,Backend-Library,C,C,,"In NoiseModel.h, kraus_op data is templated (cudaq::complex). However, when generating Python binding (py_NoiseModel.cpp), this is compiled only with double precision config. This caused bogus Kraus channel data for single-precision targets, e.g., when the channel is created in Python with cudaq.KrausChannel",It is a backend library config problem for the Python binings. Model templates and their Python exposure seem to be inconsistent.,Needs verification that c or cpp File is built for both float and double. Underlying issue is numeric implementation error.
NVIDIA/cuda-quantum,2541,https://github.com/NVIDIA/cuda-quantum/issues/2541,Python ast bridge and kernel builder do not properly annotate kernels,closed,2025-01-24T21:20:06Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,B ,B ,B2, A kernel function must be annotated with the cudaq-kernel attribute. Python doesn't do this making proper identification of kernel functions impossible,"Python front end generates Q-IR, bridge omits the kernel annotation in the produced metadata, independent of backend simulator or environment.",metadata validator could check any callable exposed as Cuda-Q kernel carries the cudaq-kernel attribute and flag missing annotations before compilation. Would requiere lots of effort with metadata checks. 
NVIDIA/cuda-quantum,2540,https://github.com/NVIDIA/cuda-quantum/issues/2540,Python AST Builder assigns quantum memory artifacts to classic memory locations,closed,2025-01-24T21:10:55Z,API-/Usage-/Logic-Bug (High-Level),Backend-Library,B ,B ,B2,"Lowering generates a pattern that copies quantum references into a classical array, which is prohibited according to IR semantics.","Backend library: The problem lies in the code generator/optimizer passes for Quake/CC-IR, not in the user frontend.","(potentially avoidable at compile time, advanced analysis): An IR verifier could prohibit quake.ref from being stored in classic data structures (local pattern, but special check required)."
NVIDIA/cuda-quantum,2538,https://github.com/NVIDIA/cuda-quantum/issues/2538,Python kernel builder uses empty strings for measurement names,closed,2025-01-24T20:04:52Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic,A,A,,"Python kernel builder generates measurement operations with empty names, even though this is defined as illegal in the IR.","The error is in the high-level builder, which generates invalid IR.",A simple local check “Name must not be empty” in the Builder or IR Verifier would deterministically prevent this pattern.
NVIDIA/cuda-quantum,2536,https://github.com/NVIDIA/cuda-quantum/issues/2536,Compile error when using `cudaq::adjoint` on quantum kernels with non-trivial `for` loop conditions,open,2025-01-24T14:47:30Z,API-/Usage-/Logic-Bug (High-Level),Backend-Library,C,C,,"From the user's point of view, correct loops (e.g., i < size-1 or while (i < size)) cannot be adjusted and lead to compiler errors.","The problem stems from the MLIR/CFG/adjoint passes in the compiler, not from the environment or backend selection.",The lack of support for certain control flow forms in the adjoint pipeline is a compiler implementation problem that cannot be avoided by additional checks on the user code.
NVIDIA/cuda-quantum,2525,https://github.com/NVIDIA/cuda-quantum/issues/2525,cudaq.control() doesn't work with exp_pauli(),closed,2025-01-21T17:57:24Z,Performance-/Numerik-Bug ,Backend-Library ,C,C,,"The circuit perform the exp_pauli() on both the |0> and the |1> subspaces on the state. If I instead, perform a cudaq.control() with a different gate, say Ry(), I get the correct result. ",The problem resides in the backend library’s implementation of exp_pauli and its interaction with cudaq.control for controlled multi-qubit exponentials,This is a semantic error in the backend’s numerical logic for controlled exp_pauli. It cannot be ruled out by generic compile-time or static type checks and requires runtime validation
NVIDIA/cuda-quantum,2457,https://github.com/NVIDIA/cuda-quantum/issues/2457,`mx` operation unsupported in OpenQASM conversion,closed,2024-12-09T19:27:09Z,Backend-/Framework-Integrations-Bug,Framework-Integration,C,C,,"Currently, a CUDA-Q kernel containing the mx measurement operation cannot be translated into OpenQASM 2.0 via cudaq.translate()",Possible error in integration btw Cuda-Qs Quake IR and the OpenQASM 2 backend.,a static checker couldn't generally know which operations a given translation backend supports
NVIDIA/cuda-quantum,2453,https://github.com/NVIDIA/cuda-quantum/issues/2453,Float comparison operator throws throws error in cudaq.kernel,closed,2024-12-05T21:43:47Z,API-/Usage-/Logic-Bug (High-Level),Backend-Library,B ,B ,B2,"Attempting to use comparison operators like < throws an error in a cudaq.kernel. Used kernel is a = 0.5 < 1.0. This will throw: error: 'arith.cmpi' op operand #0 must be signless-integer-like, but got 'f64' ","the high-level kernel code is valid Python, but the bridge emits an arith.cmpi op with the wrong type constraints ",A IR validator or operator-compatibility check could statically flag that float operands are being fed to an integer-only compare op 
NVIDIA/cuda-quantum,2452,https://github.com/NVIDIA/cuda-quantum/issues/2452,Error not thrown when broadcasting custom unitary to a qvector.,open,2024-12-05T19:24:02Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic,A,A,,"When attempting to broadcast a custom unitary to a qvector, an error is not thrown. In the reproducer below, the kernel produces an incorrect result when sampled. ",The issue is in the high-level Python API / kernel-call that wires cudaq.qvector arguments into registered custom operations ,A front-end checker could statically compare the arity implied by the custom-op matrix with the argument shape 
NVIDIA/cuda-quantum,2434,https://github.com/NVIDIA/cuda-quantum/issues/2434,cudaErrorIllegalAddress error when using exp_pauli(...) on multiple GPUs,open,2024-11-28T15:14:43Z,Performance-/Numerik-Bug,Backend-Library,C,C,,"When using exp_pauli(pauli string) in a kernel, cudaq.observe(...) and cudaq.sample(...) calls result in the error:  RuntimeError: cudaErrorIllegalAddress ",Error arises in the CUDA-Q backend library that implements multi-GPU execution of exp_pauli. ,Illegal address on the GPU is a low-level runtime bug. Nothing which could be detected reasonably within compiletime
NVIDIA/cuda-quantum,2425,https://github.com/NVIDIA/cuda-quantum/issues/2425,[braket] Reorder global register to be in original qubit allocation order,open,2024-11-27T01:25:48Z,Backend-/Framework-Integrations-Bug,Framework-Integration,C,C,,"Reorder global register to be in original qubit allocation order for braket backend, if we run any qubit mapping. ",A framework integration issue in the Braket backend’s mapping layer. Cuda-Q kernel and API seem to be fine.  ,Whether a backend reorders qubits after mapping is a backend-specific integration detail. A generic compile-time checker on user code cannot easily see or forbid this.
NVIDIA/cuda-quantum,2415,https://github.com/NVIDIA/cuda-quantum/issues/2415,Failure when building `OptTransforms` library alone.,closed,2024-11-25T19:12:49Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment,B ,B ,B1,Partial build of OptTransforms does not generate missing headers and fails during compilation.,"This is a build-system / CMake dependency-graph issue for generated headers in the OptTransforms/Optimizer CodeGen pipeline (e.g., missing generation of Passes.h.inc when building OptTransforms in isolation), not an exp_pauli / cudaq.control backend-library problem. ","(potentially avoidable at compile time, advanced analysis): A build system check could specifically verify whether all generated includes are correctly created as dependencies."
NVIDIA/cuda-quantum,2306,https://github.com/NVIDIA/cuda-quantum/issues/2306,Unified memory support on GH200 Grace Hopper,closed,2024-10-21T16:49:29Z,Performance-/Numerik-Bug ,Backend-Library,C,C,,"Simulation fails with ""requested size is too big,"" even though hardware with unified memory should actually allow for more qubits.","Limitations arise from cuQuantum/backend memory allocation (e.g., cudaMalloc vs. cudaMallocManaged), not from user code or build.",The use of unified memory is an implementation/architecture issue on the backend that cannot be “avoided” by user-side compile-time checks.
NVIDIA/cuda-quantum,2279,https://github.com/NVIDIA/cuda-quantum/issues/2279,Inconsistent behavior with mid-circuit measurements while sampling if NO reset is performed after the measurement,open,2024-10-14T22:58:54Z,Performance-/Numerik-Bug,Backend-Library,C,C,,Semantically identical kernels produce different __global__ distributions because mid-circuit measures do not collapse the state.,"The cause lies in the implementation of the simulators (except for stim), which incorrectly model mid-circuit measurements.",This is a fundamental question of simulation semantics and can only be resolved by changing the simulator implementations.
NVIDIA/cuda-quantum,2274,https://github.com/NVIDIA/cuda-quantum/issues/2274,Erroneous mid-circuit measurements while sampling if a reset is performed after the measurement,closed,2024-10-14T15:30:10Z,Performance-/Numerik-Bug,Backend-Library,C,C,,Mid-circuit measurements are being reported with incorrect values if a reset follows them. I believe this affects all of the existing simulators. ,The problem sits in the simulator backend. the reset implementation does not flush pending sampling tasks ,Whether the simulator correctly flushes its internal sampling queue on reset is purely a runtime implementation detail 
NVIDIA/cuda-quantum,2271,https://github.com/NVIDIA/cuda-quantum/issues/2271,Mid-circuit measurements are not handled properly when using `__qpu__` attributes on C++ functions or lambdas,open,2024-10-14T00:40:22Z,Backend-/Framework-Integrations-Bug,Framework-Integration,C,C,,"Runtime cannot resolve function names from __qpu__ kernels, so mid-circuit conditionals are handled incorrectly.","Problem lies in runtime/integration: Kernel names of __qpu__ functions/lambdas are not resolved at runtime; as a result, conditional feedback is not recognized (kernelHasConditionalFeedback ? false).",Whether kernel names end up correctly in the runtime metadata map is an internal integration issue and cannot be avoided by static analysis of the user code.
NVIDIA/cuda-quantum,2249,https://github.com/NVIDIA/cuda-quantum/issues/2249,anyon target is not stable in CI,closed,2024-10-03T20:05:12Z,Performance-/Numerik-Bug,Backend-Library,C,C,,The anyon target is not stable in CI: target tests fail when anyon is selected and stdout is empty/incorrect. ,"The problem is in the anyon target implementation and its CI/target-test execution path, not in simulator reset/sampling semantics. ",This is an internal target/backend stability issue; user-side compile-time checks cannot prevent CI-time target instability.
NVIDIA/cuda-quantum,2240,https://github.com/NVIDIA/cuda-quantum/issues/2240,List defined inside a kernel passed into subkernel throws an error,open,2024-10-01T12:25:32Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,"A list created inside a kernel and then passed into a subkernel causes a compilation failure (call operand type mismatch / list lowering issue), while passing a list literal directly works. "," Problem in the interaction between high-level kernel/draw API and backend/library call, not in the user kernel itself.",The error lies in the specific implementation of the draw/backend path and cannot be prevented by additional static checks on the user code.
NVIDIA/cuda-quantum,2196,https://github.com/NVIDIA/cuda-quantum/issues/2196,FuseWithConstantArray on ExtractValueOp always returns success(),closed,2024-09-06T16:20:11Z,API-/Usage-/Logic-Bug (High-Level),Backend-Library,B ,B ,B2,"The MLIR pass returns ""success"" even though no pattern was applied, thereby blocking further canonicalization patterns.","The bug is in the compiler/optimizer pass of Quake/CC-IR, not in the user API or environment.","An IR/pass validator could statically find the inconsistency “success without change”; however, this requires special compiler analyses, not just simple type checks."
NVIDIA/cuda-quantum,2185,https://github.com/NVIDIA/cuda-quantum/issues/2185,`nvidia` target: simulation errors when setting `CUDAQ_MAX_CPU_MEMORY_GB` beyond system memory capacity,open,2024-09-02T04:18:07Z,Config-/Environment-Bug,Runtime-/Framework-Runtime ,C,C,,"Documented environment variable does not behave robustly for ""unlimited"" or too large values and leads to runtime errors / incorrect results.","The error lies in the runtime logic of how the simulators interpret host/GPU memory limits, not in the build or user API.",The relationship between physical memory and runtime configuration cannot be detected by analyzing the user code; a more robust runtime implementation is required.
NVIDIA/cuda-quantum,2157,https://github.com/NVIDIA/cuda-quantum/issues/2157,Drawing conditional measurement operations,open,2024-08-27T09:28:43Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,"The drawing function ignores conditional gates based on measurement results, thereby violating the expected visualization semantics.","The error lies in the high-level display/visualization logic, regardless of the backend and numerics.","The problem is a lack of functionality in the Draw API; compile-time checks on the kernel code cannot “prevent” this, only the implementation itself can fix it."
NVIDIA/cuda-quantum,2110,https://github.com/NVIDIA/cuda-quantum/issues/2110,C++ segfault when passing callable kernel to another kernel from library,open,2024-08-19T23:22:46Z,Backend-/Framework-Integrations-Bug,Framework-Integration,C,C,,"Passing a callable quantum kernel across translation units (library-defined kernel wrapped as std::function and invoked from another kernel) triggers a C++-side segfault in CUDA-Q, despite being valid C++ usage.","The problem is in the toolchain/runtime's handling of kernel symbol identity and callable kernel plumbing across translation units / function objects, not in the user algorithm.",This is a runtime/toolchain integration limitation; generic compile-time checks on user code cannot reliably prevent it without overly restricting valid C++ patterns (Class C).
NVIDIA/cuda-quantum,2092,https://github.com/NVIDIA/cuda-quantum/issues/2092,Incorrect spin op expression evaluation,closed,2024-08-14T20:18:13Z,Performance-/Numerik-Bug,Backend-Library,C,C,,Evaluating certain spin operator expressions produces an incorrect matrix (order-dependent: one ordering yields wrong results while the reversed ordering is correct).,The defect lies in the backend library's spin-operator algebra / matrix construction logic (implementation bug in operator composition).,This is a semantic/algebraic backend bug that requires fixing library logic; it cannot be eliminated by static checks on user code.
NVIDIA/cuda-quantum,2088,https://github.com/NVIDIA/cuda-quantum/issues/2088,Target tests appear to sometimes use files from installation directory,closed,2024-08-13T17:04:14Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment,B ,B ,B1,"Target tests sometimes pick up artifacts from a prior make install instead of the current build, making tests non-deterministic and not actually validating the build under test.","The root cause is in CMake/test configuration and path resolution (e.g., install vs build directory precedence, search paths/RPATH), not in runtime execution.","A build/test validation step can deterministically detect this (e.g., assert tests reference build-tree artifacts), so it is preventable via pre-run configuration checks (Class B1)."
NVIDIA/cuda-quantum,2076,https://github.com/NVIDIA/cuda-quantum/issues/2076,`qvector` initialization from state does not work unless no other qubits have been allocated yet,closed,2024-08-12T13:13:51Z,Performance-/Numerik-Bug,Backend-Library,C,C,,"Initialization of q = cudaq.qvector(vec) unexpectedly affects the upstream qubit p, resulting in an incorrect measurement distribution.","Error in the implementation of the state-init routines of the nvidia-* backends, not in API usage or build.",The correctness of state preparation is purely backend algorithmics and cannot be verified in practice by type/contract checks on the user kernel.
NVIDIA/cuda-quantum,1975,https://github.com/NVIDIA/cuda-quantum/issues/1975,Synthesis fails for some kernels that use `cudaq::slice_vector`,closed,2024-07-19T20:59:04Z,API-/Usage-/Logic-Bug (High-Level),Framework-Integration,C,C,,Using slice_vector/observe generates IR that is not supported by the synthesizer/NVQC path.,Bug in the interaction between the CUDA-Q front end (pointer/slice API) and the downstream synthesis/NVQC infrastructure.,"This is a gap/compatibility issue in the synthesizer. additional analysis of the user code would not prevent it, but would only generate earlier error messages."
NVIDIA/cuda-quantum,1957,https://github.com/NVIDIA/cuda-quantum/issues/1957,[MLIR mode] Compile error for `pauli_word` argument,closed,2024-07-18T05:53:38Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,"In MLIR mode, compiling a kernel that takes a cudaq::pauli_word and passes it to exp_pauli(theta, q, pauli) fails with error: could not determine string argument",Issue is probably in the compiler and not API misuse or backend simulation.,Would need a type validator for the MLIR path. Advanced knowledge and implementation in combination with specialised compiler-level analysis instead of some kind of type checking
NVIDIA/cuda-quantum,1946,https://github.com/NVIDIA/cuda-quantum/issues/1946,current version of cudaq.draw throws error if kernel uses exp_pauli,closed,2024-07-17T16:47:33Z,Backend-/Framework-Integrations-Bug,Framework-Integration,C,C,,"cudaq.draw() fails for kernels that include exp_pauli(...): the visualization path triggers an initialization / simulator setup error, even though the same kernel can execute normally (e.g., via sample()/observe())","The fault is in the draw/visualization pipeline and its integration with the backend (e.g., the custatevec-based path used by draw()), not in the user kernel semantics. It is an interaction bug between the front-end drawing code and the backend initialization logic.",This is a draw/visualization-path backend initialization bug (custatevec applyExpPauli fails in cudaq.draw while execution via sample() works) and cannot be prevented by user-side compile-time checks 
NVIDIA/cuda-quantum,1925,https://github.com/NVIDIA/cuda-quantum/issues/1925,[CI] [tensornet] Attempt to set target causes fatal error in some OS environments,open,2024-07-12T23:03:00Z,Backend-/Framework-Integrations-Bug,Framework-Integration,C,C,,Test that runs through all targets with parameters causes CI runs to crash if optional simulators are not correctly available/integrated.,"The problem lies in the interaction between the test infrastructure, set_target, and optional backends in different OS/CI environments.",This is about robust implementation of target detection/error handling in code and CI; this cannot be prevented in a meaningful way by additional compile-time analyses of user kernels.
NVIDIA/cuda-quantum,1924,https://github.com/NVIDIA/cuda-quantum/issues/1924,[Python] Remote execution speed up doesn't support custom operations,open,2024-07-12T21:51:44Z,Backend-/Framework-Integrations-Bug,Framework-Integration,C,C,,"Local registration of custom_h works, but the remote server reports ""known kernels are []"" and cannot execute the kernel.",The error lies in the integration between the Python front end/custom op registry and the remote execution service.,Whether custom operations are correctly transported/registered to the remote backend is an integration issue and cannot be detected by static analysis of the user code.
NVIDIA/cuda-quantum,1909,https://github.com/NVIDIA/cuda-quantum/issues/1909,cudaq.observe causes a memory leak,closed,2024-07-10T05:34:33Z,Performance-/Numerik-Bug,Runtime-/Framework-Runtime ,C,C,,Memory usage increases continuously with many observe calls and is not released.,"The problem lies in the resource/memory management of the runtime/execution engine, not in the compiler or API semantics",Memory leaks of this type are classic runtime implementation bugs and cannot be prevented by compile-time analyses of the user program.
NVIDIA/cuda-quantum,1895,https://github.com/NVIDIA/cuda-quantum/issues/1895,Endian is inconsistent between State and SpinOperator.to_matrix,closed,2024-07-08T07:26:25Z,Performance-/Numerik-Bug,Backend-Library ,C,C,,Expected value from observe and direct calculation state @ to_matrix() @ state deliver different results due to different endianness conventions.,The error lies in the implementation of SpinOperator.to_matrix or the assignment of the operator to the state basis.,Inconsistent endianness is a design/implementation error in the library and cannot be avoided by static analysis of user kernels.
NVIDIA/cuda-quantum,1894,https://github.com/NVIDIA/cuda-quantum/issues/1894,Controlled exp_pauli is not correct,closed,2024-07-08T07:08:46Z,Performance-/Numerik-Bug ,Backend-Library ,C,C,,"Applying cudaq.control(...) to a unitary that uses exp_pauli(...) produces an incorrect state (the Hadamard-test example does not yield the expected Bell state amplitudes), while an equivalent construction using a simple gate (e.g., X) behaves correctly.","The defect is in the backend/library implementation of controlled exp_pauli (i.e., how the controlled version of the exp_pauli operation is constructed/lowered), not in user code syntax or environment setup.",This is a semantic/numerical backend correctness bug: it requires fixing the implementation of the controlled exp_pauli path and cannot be prevented by generic compile-time or user-side static checks.
NVIDIA/cuda-quantum,1875,https://github.com/NVIDIA/cuda-quantum/issues/1875,issue with if condition after mid circuit measurement,closed,2024-07-01T15:17:07Z,API-/Usage-/Logic-Bug (High-Level),Backend-Library,C,C,,Semantically equivalent control logic with and and nested if statements leads to different behavior; a is not set in the second case.,"The cause is the code generation/lowering logic for Boolean expressions and measurement results, not the environment or backend selection."," This is a compiler/IR lowering bug; additional static checks on the user kernel would not prevent it, only implementation fixes in the codegen."
NVIDIA/cuda-quantum,1874,https://github.com/NVIDIA/cuda-quantum/issues/1874,Execution hangs on OpenSUSE when installed via installer,closed,2024-07-01T13:16:37Z,Performance-/Numerik-Bug,Runtime-/Framework-Runtime ,C,C,,Execution on GPU backends under OpenSUSE is blocked or only continues after a timeout.,The problem lies in the interaction between CUDA-Q runtime and libc++/OS-specific environment when starting/executing GPU backends.,OS/runtime-specific hangers of this type are implementation/configuration details of the runtime and cannot be avoided by additional compile-time analyses of the user code.
NVIDIA/cuda-quantum,1871,https://github.com/NVIDIA/cuda-quantum/issues/1871,Calling the same quantum kernel in cudaq.control and cudaq.adjoint in the main kernel give error.,closed,2024-06-30T13:35:07Z,API-/Usage-/Logic-Bug (High-Level),Framework-Integration ,C,C,,A valid pattern (calling the same kernel via cudaq.control and cudaq.adjoint inside a parent kernel) fails with an internal error like “does not reference a valid function.” ,"The root cause is in MLIR/codegen handling of controlled/adjointed function symbols, not in Python usage or the environment. ",This is a compiler/codegen integration issue; user-side compile-time checks cannot meaningfully prevent it 
NVIDIA/cuda-quantum,1860,https://github.com/NVIDIA/cuda-quantum/issues/1860,Build dependency missing for python?,closed,2024-06-27T20:45:25Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment ,B ,B ,B1,suspect that there may be missing boilerplate regarding copying the .py files in our cmake recipes. ,This is a build / environment configuration issue in the CUDA-Q installation flow ,"A simple configure-time check in CMake could fix this problem, so B1"
NVIDIA/cuda-quantum,1813,https://github.com/NVIDIA/cuda-quantum/issues/1813,DepolarizationChannel not completely depolarizing,closed,2024-06-13T16:47:35Z,Performance-/Numerik-Bug,Backend-Library,C,C,,Depolarizing channel with error probability 1 generates <Z> expectation values that depend on the rotation angle instead of being 0.,"The error lies in the implementation of DepolarizationChannel or density-matrix-cpu, not in the high-level API.",Incorrect channel semantics is purely an implementation/numerical bug in the simulator and cannot be prevented by type/contract checks in the user code.
NVIDIA/cuda-quantum,1809,https://github.com/NVIDIA/cuda-quantum/issues/1809,Kernels do not take as input a list[list[int]] type object,open,2024-06-13T15:57:42Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,A,A,,"Passing a nested Python container list[list[int]] into a @cudaq.kernel fails at runtime with Cannot infer CUDA-Q type from provided Python type (!cc.stdvec<!cc.stdvec>), even though the docs show examples that suggest this should work.",The issue is in the Python front-end / type-mapping layer that infers CUDA-Q types from Python annotations and values; it cannot correctly lower nested list containers into the expected CUDA-Q/CC-IR vector-of-vector type. ,This is a compile-time/pre-execution preventable API/type-support issue: a front-end validator or static type check could deterministically reject unsupported nested containers (or support them) before execution. Fits Class A
NVIDIA/cuda-quantum,1804,https://github.com/NVIDIA/cuda-quantum/issues/1804,[python] Combining `cudaq` module with `multiprocesssing` module can result in deadlock,closed,2024-06-12T14:30:28Z,Config-/Environment-Bug,Runtime-/Framework-Runtime ,C,C,,Using the default fork startup method with a multithreaded CUDA-Q process leads to deadlock.,"The problem arises in the runtime interaction between the Python process start method and CUDA-Q runtime, not in the build or kernel code.","Fork-vs-Spawn-Probleme bei Multithreading sind typische Runtime-/Systemeffekte, die nicht sinnvoll durch statische Analyse des User-Programms verhindert werden k�nnen."
NVIDIA/cuda-quantum,1799,https://github.com/NVIDIA/cuda-quantum/issues/1799,Incorrect circuit compilation when using some nested loops,closed,2024-06-11T11:24:06Z,API-/Usage-/Logic-Bug (High-Level),Backend-Library,C,C,,"Decorator path compiles nested loops with for k in range(j+1, N) into a logically incorrect circuit.","The cause is an LLVM/MLIR codegen/loop normalization bug in the compiler pipeline, not in the Python frontend or environment.","(not reasonably avoidable at compile time). Miscompilation due to upstream loop passes can practically only be fixed by fixes/mitigations in the compiler, not by additional type/contract checks on user code."
NVIDIA/cuda-quantum,1784,https://github.com/NVIDIA/cuda-quantum/issues/1784,Quake.ExpPauliOp is incomplete,open,2024-06-10T15:34:46Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,The ExpPauliOp class does not behave like a clean value type API during copy/move/assignment. This is an object/API semantic bug. ,"ExpPauliOp is part of the high-level operator API; its implementation is affected, not the backend or environment. ","Incorrect value semantics in a library class cannot be prevented by analyzing the user code, but only by correcting the class implementation. "
NVIDIA/cuda-quantum,1749,https://github.com/NVIDIA/cuda-quantum/issues/1749,`do { ... } while (false)` causes infinite loop when `--enable-mlir` is set,closed,2024-06-03T16:04:49Z,API-/Usage-/Logic-Bug (High-Level) ,Backend-Library ,C ,C ,,Using the common macro pattern do { ... } while (0) inside a __qpu__ kernel causes programs compiled with nvq++ --enable-mlir to hang at runtime,"Issue seems to be in the MLIR-based compilation / backend path of CUDA-Q. the kernel is valid C++ code, but only the MLIR-enabled pipeline produces IR that leads to an apparent infinite loop during execution ",Whether this specific do { ... } while (0) pattern is lowered correctly depends on internal MLIR control-flow handling. Generic frontend type checker on code would not catch this
NVIDIA/cuda-quantum,1726,https://github.com/NVIDIA/cuda-quantum/issues/1726,Cannot call C++ __qpu__ function from within another kernel if parameters contain vector of cudaq::measure_results,closed,2024-05-29T16:53:45Z,API-/Usage-/Logic-Bug (High-Level),Framework-Integration,B ,B ,B2,"Valid C++ code (xor_result with measure_result vector), but MLIR inlining pass incorrectly flags ""recursion.""",The problem lies in aggressive early inlining pass + type IR mapping between C++ and MLIR.,"A call graph analyzer could distinguish between genuine and false recursion, but this requires advanced data flow analysis."
NVIDIA/cuda-quantum,1703,https://github.com/NVIDIA/cuda-quantum/issues/1703,Segfault during circuit simulation with 2^19 controlled rotation gates,closed,2024-05-22T16:18:59Z,Performance-/Numerik-Bug,Runtime-/Framework-Runtime ,C,C,,"The problem only occurs with a very large number of cr1/crx gates (loop with 2**19 iterations) and manifests itself as a segfault across multiple targets - typical for a resource/performance bug (e.g., stack/heap exhaustion, IR too large, etc.), not for pure API or configuration issues.","Since the behavior is cross-target and tied to MLIR enablement, it points to a bug in generic runtime/JIT/IR handling (e.g., scheduling, memory management), not in a specific backend library.","Whether a specific circuit size leads to a segfault depends on internal data structures, JIT strategies, and resource limits; this cannot be verified purely statically, but is rather a question of implementation/runtime."
NVIDIA/cuda-quantum,1682,https://github.com/NVIDIA/cuda-quantum/issues/1682,break within two loops is not handled right.,closed,2024-05-15T12:45:44Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,"The user employs valid language constructs (while loop, measurement, if res: break); however, the compiler produces an incorrect IR (arity mismatch of cc.unwind_break) - this is a frontend/control flow lowering bug.",This affects the logic that translates Python kernels with classical control and quantum measurement into a consistent IR; backend and env are secondary.,"The implementation of control flow lowering is broken here; additional static checks on the user code would not prevent the bug (the compiler should support this pattern), more robust pass implementation/verification is needed."
NVIDIA/cuda-quantum,1670,https://github.com/NVIDIA/cuda-quantum/issues/1670,[c++] qvector initialization from vector of doubles fails for f32 simulator,closed,2024-05-13T20:07:46Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,A,A,,"Semantically correct user code (double vector as init state), but the API/kernel logic does not automatically accept type conversion (FP64?FP32), even though the codebook provides for it.","The problem lies in the Qvector constructor semantics and their error handling, not in the backend library or environment.",Static type checking could detect precision mismatch directly when the constructor is called; better overloads or type constraints would catch the error at compile time.
NVIDIA/cuda-quantum,1663,https://github.com/NVIDIA/cuda-quantum/issues/1663,Python version on Quantum Cloud does not allow exponentiation operator,closed,2024-05-11T03:30:04Z,Backend-/Framework-Integrations-Bug,Framework-Integration,B ,B ,B1,"The code runs locally, but legalizing math.ipowi fails on the remote target; this is a problem in the integration of Python/IR lowering with the passes/constraints of the cloud backend.",This affects the layer that connects the Python kernel + IR pass pipeline to the remote backend (nvqc); multiple targets share the same frontend/pass logic.," One could imagine a (domain-specific) static compatibility analysis that checks in advance whether all ops (** ? ipowi) used are legalizable for a given target/pass pipeline set, and if not, provides a clear compile-time error message early on; This is advanced, but conceptually possible."
NVIDIA/cuda-quantum,1662,https://github.com/NVIDIA/cuda-quantum/issues/1662,Subtraction of variables gives unhandled BinOp.Sub error within a python kernel,closed,2024-05-10T21:46:43Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,"A syntactically completely harmless expression in the Python kernel fails, while an equivalent rewritten form works. This suggests incomplete/flawed high-level lowering/AST bridging logic."," The error occurs when translating the Python AST into the internal IR (kernel front end), not in the backend or in the environment."," Whether a particular AST pattern is supported in the compiler is an implementation issue; this cannot be prevented by additional analysis of the user code, but only by more robust implementation/testing of the front end."
NVIDIA/cuda-quantum,1620,https://github.com/NVIDIA/cuda-quantum/issues/1620,[Python Kernel] `bool` to `int` type casting issue,closed,2024-05-07T03:41:09Z,API-/Usage-/Logic-Bug (High-Level) ,Backend-Library ,B ,B ,B2,"A measurement result bit = mz(aux) is lowered to IR that sign-extends the i1 value to i64 (sext i1 %7 to i64) and then compares it to 1. Since true becomes -1 under signed extension, the icmp eq i64 %8, 1 condition is never satisfied, so the if bit == 1: branch is logically wrong","The defect is in the kernel codegen. The high-level kernel code is valid, but the generated IR compearision ins obviously incorrect. ",A specialised IR validator or formal check over the codegen pipeline could detect inconsistent patterns like sext i1 followed by comparison with 1 for a logical boolean. and enforce zero-extension or correct comparison 
NVIDIA/cuda-quantum,1618,https://github.com/NVIDIA/cuda-quantum/issues/1618,`MidCircuitMeasurementAnalyzer` doesn't handle all cases of measurement assigned variables ,closed,2024-05-07T01:02:31Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,Certain types of conditions are not handled correctly in the Analysis Helper. Llogic/oversight bug in the high-level analysis tool.,"It affects the internal analysis/frontend logic (AST/IR bridging), not build, backend, or runtime.",The vulnerability lies in the helper function itself; user code analysis cannot prevent this as long as the helper is not fully implemented.
NVIDIA/cuda-quantum,1571,https://github.com/NVIDIA/cuda-quantum/issues/1571,make check-targets doesn't have all dependencies in the CMakeLists.txt files,open,2024-04-25T23:00:55Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment,B ,B ,B1,"The build/install logic does not correctly update runtime libraries when switching branches, resulting in link/runtime errors.",The problem occurs in the build/CI/install environment before anything is simulated or compiled.,"A precisely modeled build graph or tooling that forces dependent targets to rebuild when branches change could detect such errors, but this is a more complex build/analysis task."
NVIDIA/cuda-quantum,1566,https://github.com/NVIDIA/cuda-quantum/issues/1566,Cannot pass a list of Pauli words to `observe_async`,closed,2024-04-25T14:24:56Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,"Synchronous observe accepts a list of Pauli strings, whereas observe_async does not. Inconsistent API/contract logic.","The error lies in the Python bindings or the high-level API (overloads/conversions), not in simulation, build, or environment.","This is a gap in the implementation of the async overload; additional analysis of the user code does not prevent this, a library fix is required."
NVIDIA/cuda-quantum,1539,https://github.com/NVIDIA/cuda-quantum/issues/1539,ChemistryTester bug when nvidia target is available,closed,2024-04-18T12:37:56Z,Backend-/Framework-Integrations-Bug,Framework-Integration,C,C,,"The Python/PySCF bindings initialize CUDA-Q and set the default target to nvidia, while the tester is linked to QPP FP64 - integration/target selection conflict.","The problem lies in the interaction between the Python helper library, target management, and C++ tester (mix of different backends in one pipeline).",Global target switches and precision mismatches caused by such integration paths are runtime/configuration details that cannot realistically be verified by static analysis of the Quantum user code.
NVIDIA/cuda-quantum,1529,https://github.com/NVIDIA/cuda-quantum/issues/1529,Calling kernel functions with list parameters gives incorrect results,closed,2024-04-17T17:05:02Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,"The kernel test_param(i: int, v1: list[int]) -> int should return i each time, but returns 42 four times. Logic/binding bug in the Python kernel call implementation.","The error lies in the way Python call sites/arguments are mapped in IR/Runtime, i.e., in the high-level language/framework layer.",Incorrect capturing/assignment of arguments is an internal binding/runtime problem that cannot be prevented by additional type or CT analyses of the user code.
NVIDIA/cuda-quantum,1498,https://github.com/NVIDIA/cuda-quantum/issues/1498,Output discrepancy when args of mz are in a list vs when comma separated ,closed,2024-04-11T06:39:51Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,"The measurement API behaves inconsistently: qubits passed as a list return the correct bit length, but comma-separated arguments do not. API/semantics bug.","This concerns the Python frontend/measurement API and its result format, not the backend.",The incorrect argument handling is a library implementation problem; CT analyses of the user code would not change anything.
NVIDIA/cuda-quantum,1469,https://github.com/NVIDIA/cuda-quantum/issues/1469,Cannot run Python range-based for loops through the synthesizer (affects NVQC),closed,2024-04-02T23:58:05Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,"The standard Python pattern (for i in range(len(parms)): parms[i]) leads to an internal IR/pass error, while the variant for i in parms works.  Frontend/IR generation bug.","The problem arises in Python kernel MLIR generation and subsequent lowering, not in the simulator or build.",The incorrect handling of constant arrays and cc.get_const_element in LowerToQIR is an internal pass weakness that cannot be compensated for by analyzing the user code.
NVIDIA/cuda-quantum,1464,https://github.com/NVIDIA/cuda-quantum/issues/1464,`cnot` operation is not compiled properly in MLIR mode,closed,2024-04-02T02:46:37Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,The shorthand cnot violates its semantics when MLIR is enabled because it is translated into two single-X gates instead of a controlled operation- Asemantics/compiler logic bug.,The incorrect translation occurs in the frontend/MLIR lowering of the kernel code before a specific backend comes into play.,"An incorrectly implemented lowering of the operator can only be fixed by fixing/verifying the compiler, not by adding additional checks to the user kernel."
NVIDIA/cuda-quantum,1432,https://github.com/NVIDIA/cuda-quantum/issues/1432,Handle references to constant data in `GenerateDeviceCodeLoader`,closed,2024-03-22T02:29:15Z,API-/Usage-/Logic-Bug (High-Level),Framework-Integration,C,C,,The design/implementation logic of module excision relies solely on the call graph and overlooks constantly referenced data. Maybe is a conceptual logic error in the compiler pipeline.,"This affects the interaction between the kernel module, host code, and compiler IR when extracting the kernel module, i.e., the integration/compiler layer.","Here, the analysis itself (call graph only) is insufficient; additional CT checks on the user code do not change anything as long as the excision algorithm does not include constant data."
NVIDIA/cuda-quantum,1431,https://github.com/NVIDIA/cuda-quantum/issues/1431,Endian representation bug in `QppCircuitSimulator::observe`,open,2024-03-22T02:25:40Z,Backend-/Framework-Integrations-Bug,Backend-Library,C,C,,The change in qpp state vector endianness was not consistently applied in QppCircuitSimulator::observe with Hamiltonian matrix generation (spin_op::to_matrix) - integration error between two backend components.,"The bug is entirely in the qpp backend implementation (state vector layout vs. Hamiltonian matrix), not in the high-level framework.",Whether Matrix and Statevector use the same endianness is an internal backend detail that cannot be verified by analyzing the user code.
NVIDIA/cuda-quantum,1421,https://github.com/NVIDIA/cuda-quantum/issues/1421,LLVM aarch64 relocation overflow,closed,2024-03-20T03:55:38Z,Performance-/Numerik-Bug,Runtime-/Framework-Runtime,C,C,,"In memory-intensive VQEs, a relocation assertion fails deep within the LLVM JIT. Resource/numerical/JIT bug, not a simple API error.","The crash occurs in the execution/JIT runtime (RuntimeDyldELF), i.e., in the runtime layer above the backend.","Such size/overflow problems in JIT/relocations cannot be avoided by type or CT analyses of the user code, but require more robust runtime implementation."
NVIDIA/cuda-quantum,1400,https://github.com/NVIDIA/cuda-quantum/issues/1400,Circuit drawer retains qubits from previously printed kernel(s),closed,2024-03-14T17:22:45Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,Drawing the same kernel leads to increasingly longer circuit diagrams due to stale global state. A logic/state bug in the Draw API.,"Affects the visualization/front-end layer (cudaq.draw), without involving the simulator or environment.","A mismanaged global state in the draw code can only be fixed by correcting the implementation, not by analyzing the user kernel."
NVIDIA/cuda-quantum,1396,https://github.com/NVIDIA/cuda-quantum/issues/1396,Batched measurement outputs dont allign to expected results ,closed,2024-03-14T14:50:03Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,The behavior of cudaq.observe with multiple Hamiltonian terms is inconsistent with the physically expected semantics for independent qubits - logic/semantics bug in the Observe API.,"The problem lies in the way the high-level observe routine aggregates results for lists of terms, not in the backend or build.","The error lies in the internal implementation of the observe logic; additional compile-time checks on the user code could not prevent this, a library fix is required."
NVIDIA/cuda-quantum,1374,https://github.com/NVIDIA/cuda-quantum/issues/1374,nvqpp_SampleAsync fails on machines with multiple GPUs,closed,2024-03-12T16:04:15Z,Backend-/Framework-Integrations-Bug ,Runtime-/Framework-Runtime ,C,C,,"The official Async Sample CTest crashes with double-free/heap corruption when using multi-GPU/MQPU. An integration/runtime bug (MQPU, allocator, async scheduling), not purely a performance bug. ","The error occurs in the running test binary in heap/runtime management, not in the build or high-level frontend. ",Double-free/heap corruption errors in internal runtime/allocator code are classic implementation problems; they cannot be avoided by compile-time analysis of user code. 
NVIDIA/cuda-quantum,1367,https://github.com/NVIDIA/cuda-quantum/issues/1367,Synthesizer produces error when mixing certain argument types,closed,2024-03-11T15:54:51Z,Performance-/Numerik-Bug ,Framework-Integration ,C,C,,"A synthesis process for a kernel leads to std::bad_alloc, apparently because an incorrect offset causes a structure that is much too large to be interpreted/allocated ? resource/index/numerical error. ","The error lies in the interaction between argument layout and synthesizer logic (host data IR/Runtime), i.e., in the compiler/synthesizer integration layer. ",An incorrectly calculated offset in the synthesizer is an implementation bug; it does not make sense to prevent this through static analysis of user programs. 
NVIDIA/cuda-quantum,1257,https://github.com/NVIDIA/cuda-quantum/issues/1257,Duplicate quake code in `cudaq::get_quake_by_name` if inlining is disabled,closed,2024-02-20T01:48:47Z,API-/Usage-/Logic-Bug (High-Level) ,Framework-Integration ,C,C,,"A kernel that calls another twice should result in a clean module structure; instead, the callee function is defined twice. A code/logic bug. ","The double definition arises in MLIR/Quake code generation, i.e., in the integration of __qpu__ front ends with the IR/compiler infrastructure. ",This is an internal error in the code generator; additional analysis of the user code will not change anything as long as the generator is implemented incorrectly. 
NVIDIA/cuda-quantum,1218,https://github.com/NVIDIA/cuda-quantum/issues/1218,Out of scope kernel ,closed,2024-02-13T09:40:16Z,API-/Usage-/Logic-Bug (High-Level) ,Runtime-/Framework-Runtime ,C,C,,The user creates a kernel in a function and returns it. A completely legitimate pattern. the fact that this particular syntax leads to a segfault on nvidia-mqpu indicates a bug in the kernel lifetime/binding logic. ,"The crash occurs in the Async/MQPU runtime during execution, not during frontend lowering.",Object lifetimes and memory management in runtime/binding code are internal implementation details; compile-time analyses of user code are of no help here.
NVIDIA/cuda-quantum,1215,https://github.com/NVIDIA/cuda-quantum/issues/1215,`cudaq::adjoint` not handling double adjoint.,closed,2024-02-12T22:28:33Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,C,C,,A combination of rz<adj> in the kernel and adjoint(foo) effectively results in two adjoint rotations instead of the expected identity – this is a semantics/contract bug in adjoint logic. ,"It's about high-level gate and meta-operation logic (adjoint rewriting), not build, backend, or runtime environment. ","Incorrect adjoint semantics is an implementation/design problem of the library/compiler logic, not something that can be prevented by analyzing the user code at compile time. "
NVIDIA/cuda-quantum,1175,https://github.com/NVIDIA/cuda-quantum/issues/1175,Tensornet target in Python not registered for async functions ,closed,2024-02-06T15:49:53Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"When the target is set to tensornet, calling cudaq.sample_async(kernel, 10).get() segfaults in DefaultExecutionManager / runSampling, i.e., the async sampling path is not correctly wired up for the tensornet simulator target.","The error occurs during integration between the Python async API and the C++ layer, which manages various targets. The kernel itself works perfectly.","This is a backend/runtime integration bug that only manifests when executing with the tensornet target and async sampling. Fits class C, because no static property of the kernel usage that compile-time analysis could flag in advance."
NVIDIA/cuda-quantum,1168,https://github.com/NVIDIA/cuda-quantum/issues/1168,JIT compilation fails when inlining is disabled,closed,2024-02-04T12:30:01Z,API-/Usage-/Logic-Bug (High-Level),Framework-Integration ,C,C,,"A legitimate call from one __qpu__ kernel to another only works if a specific inlining pass is active; without it, an inconsistent IR – logic error occurs in the compiler pipeline. ","The bug is located in the MLIR/compiler pass pipeline (call resolution, module structure), i.e., in the interaction between the front end and the compiler/back end. ",Whether an internal pass correctly registers the target function is an implementation detail of the compiler; this cannot be verified by additional checks on the user kernel. 
NVIDIA/cuda-quantum,1159,https://github.com/NVIDIA/cuda-quantum/issues/1159,cmake dependences aren't quite right,open,2024-02-02T00:08:58Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment ,B ,B ,B1,"Executor links against RestClient, but the CMake/third-party configuration does not build RestClient. this is a build/link/packaging bug. ","The error occurs during building/linking, before any kernel is executed. ",A cleanly modeled build graph/CMake check could determine deterministically during configure/compile that a required target is missing; this is more of a build analysis issue than a runtime problem. 
NVIDIA/cuda-quantum,1136,https://github.com/NVIDIA/cuda-quantum/issues/1136,Tensornet backend scratch space allocator is prone to race condition,open,2024-01-25T01:56:05Z,Performance-/Numerik-Bug ,Backend-Library ,C,C,,The scratch size heuristic uses cudaMemGetInfo and may see incorrect free memory values in multi-tenant or multi-process setups. A resource/numerical/heuristic bug. ,This is a runtime issue in the tensornet backends scratch-space allocation (cudaMemGetInfo to scratchSize to cudaMalloc); concurrent simulator instances can race and overestimate free memory,"Race conditions in cudaMemGetInfo between multiple processes are a runtime/system issue; heuristics can be improved, but they cannot be avoided through user code analysis. "
NVIDIA/cuda-quantum,1117,https://github.com/NVIDIA/cuda-quantum/issues/1117,Intermittent CI llvm-lit test failures for `remote-mqpu` ,closed,2024-01-22T09:41:08Z,Backend-/Framework-Integrations-Bug ,Runtime-/Framework-Runtime ,C,C,,"Multiple remote mqpu tests running in parallel collide when selecting: a coordination/integration problem with the remote runtime, not purely a user configuration error. ","This affects the network/process runtime of the remote target (socket binding, daemon start), i.e., the runtime layer. ","Port collisions caused by parallel processes are typical runtime/env problems; they cannot be prevented by static analysis of Quantum programs, but only by more robust port management logic. "
NVIDIA/cuda-quantum,1108,https://github.com/NVIDIA/cuda-quantum/issues/1108,sample_async race condition,closed,2024-01-18T17:35:49Z,Performance-/Numerik-Bug ,Runtime-/Framework-Runtime ,C,C,,"A very small GHZ circuit triggers a custatevec out of memory error on nvidia-mqpu. A resource/memory management problem, not an API or configuration error on the part of the user. ","The error occurs in the interaction between MQPU runtime, sample_async, and custatevec at runtime, i.e., in the execution/runtime layer. ",How the MQPU runtime allocates memory internally is an implementation detail; this cannot be meaningfully avoided by compile-time analysis of the user code. 
NVIDIA/cuda-quantum,1087,https://github.com/NVIDIA/cuda-quantum/issues/1087,Sporadic test failure in REST platform `get_state_async` test,open,2024-01-12T04:08:39Z,Backend-/Framework-Integrations-Bug ,Runtime-/Framework-Runtime ,C,C,,"The interaction between the REST server, remote MQPU backend, and tests causes hangups in get_state_async so a integration/orchestration problem. ","Asynchrony, scheduling, timeouts, and process interaction. runtime/framework layer. ","Such deadlocks/hangs can only be resolved through better runtime implementation/monitoring, not through compile-time analysis of quantum programs. "
NVIDIA/cuda-quantum,1046,https://github.com/NVIDIA/cuda-quantum/issues/1046,Upgrade pybind11 to the latest version,closed,2023-12-19T17:13:40Z,Backend-/Framework-Integrations-Bug ,Runtime-/Framework-Runtime ,C,C,,Certain versions of pybind11 do not interact correctly with the CUDA-Q Python frontend – Integration/ABI/binding problem. ,"The effect occurs in ongoing tests in the Python binding/call layer, not when building the binaries. ",Compatibility of bindings and binary layout is a runtime/implementation issue; user code analysis does not help here.
NVIDIA/cuda-quantum,1030,https://github.com/NVIDIA/cuda-quantum/issues/1030,Incorrect QIR generated for some conditional measurements (qir_cond_for_loop-6.cpp),closed,2023-12-12T16:47:28Z,API-/Usage-/Logic-Bug (High-Level) ,Framework-Integration ,C,C,,"Correctly written user code leads to logically incorrect QIR/IR (e.g., measurement/result handling in if structures) - Compiler/semantic bug. ","The problem lies in the CUDA-Q compiler pipeline (front end so MLIR/Quake so QIR), i.e., in the integration layer. ",Faulty transformations in compiler passes are classic implementation bugs; compile-time analysis of user code does not help here. 
NVIDIA/cuda-quantum,1022,https://github.com/NVIDIA/cuda-quantum/issues/1022,`from_state` error with `kernel.qalloc()`,closed,2023-12-11T21:15:47Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,A,A,,"Semantically legitimate use (q = kernel.qalloc() and from_state(q, a)); however, the API behaves differently than for qalloc(1) and runs into an error reach of contract/semantics of the high-level API. ","The logic is in the from_state/qubit API itself (single qubit vs. qvector), not in the simulator backend or build. ","The signature/overloads could ensure at compile time that only suitable from_state calls are permitted for kernel.qalloc() or generate a clear error message early on (e.g., more strongly typed qubit/container types). "
NVIDIA/cuda-quantum,928,https://github.com/NVIDIA/cuda-quantum/issues/928,qubit-mapping has bug threading wire values,closed,2023-11-14T23:50:07Z,API-/Usage-/Logic-Bug (High-Level) ,Framework-Integration ,C,C,,"Formally valid user code leads to IR in which linear swap wires are used multiple times, causing the compiler to violate its own linearity rules. ","Errors arise in the interaction between Quake/MLIR passes (e.g., synthesis, qubit mapping, inlining) and the linearity discipline of the IR. ",This is purely a compiler/pass implementation error; it cannot be prevented by type/contract checks on the user side. 
NVIDIA/cuda-quantum,920,https://github.com/NVIDIA/cuda-quantum/issues/920,MPI is not enabled in `cudaq` Python wheels,closed,2023-11-14T02:02:49Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment ,C,C,,Wheels are delivered without MPI functionality enabled (unlike Docker/native builds)- Seems to be a  packaging/configuration error. ,"It's about build flags and wheel creation, not runtime/compiler logic. ","Such distribution errors can only be addressed by build/release checks, not by type/IR analyses of user code. "
NVIDIA/cuda-quantum,906,https://github.com/NVIDIA/cuda-quantum/issues/906,cudaq.from_state() dosn't work correctly,closed,2023-11-10T22:07:48Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,C,C,,"A valid state vector leads to another, incorrect internal state. the from_state API breaks its guaranteed semantics. ","The error lies in the mapping/representation logic of the high-level state API, not in the backend. ",This is an implementation detail of the framework state representation; user code analysis cannot prevent this. 
NVIDIA/cuda-quantum,875,https://github.com/NVIDIA/cuda-quantum/issues/875,ConvertExpr buildOp currently not specification adherent. ,closed,2023-11-07T18:49:35Z,API-/Usage-/Logic-Bug (High-Level),High-Level-API / Framework-Logic ,C,C,,"The fixup-linkage tool sets incorrect linkage/visibility properties for Mach-O/QIR artifacts, thereby breaking its own contract with the system linker. ","Bug is located in the toolchain/compiler integration layer (QIR/IR to object to host binary), not in the user code or backend. ",Incorrect linkage flags in generated IR are purely tool/implementation errors and cannot be avoided at compile time by analyzing user kernels. 
NVIDIA/cuda-quantum,873,https://github.com/NVIDIA/cuda-quantum/issues/873,Free function kernels won't work on macOS,open,2023-11-07T11:01:34Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"Chemistry/domain code is incorrectly linked to the QPP simulator (e.g., incorrect backend/precision/state handling) Integration error, not a pure build flag error. ","Layer in which Chemistry Code, CUDA Q-State, and Backend Simulator are wired. ",Such coupling errors are found through testing/CI; they cannot be effectively avoided by analyzing user kernels at compile time. 
NVIDIA/cuda-quantum,867,https://github.com/NVIDIA/cuda-quantum/issues/867,Allow for more complex builder gate signatures in library mode,closed,2023-11-06T21:16:18Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"QPP complains because CUDA-Q passes the subsystems/indexes to applyCTRL in such a way that dimension contracts are violated. This is an integration problem, not a QPP bug. ","Bug at the interface between CUDA-Q-State/register representation and QPP API (subsystem division, endianness/order). ",Whether this internal translation is correct depends solely on the library implementation; user code analysis cannot prevent this. 
NVIDIA/cuda-quantum,866,https://github.com/NVIDIA/cuda-quantum/issues/866,Unable to use IQM QPU machine name with spaces,closed,2023-11-06T12:38:06Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The problem lies in the interaction between nvq++-CLI, IQM backend, and runtime: the machine string option passed with spaces iis interpreted incorrectly, resulting in an architecture mismatch exception at runtime, even though the user specifies the correct architecture. ","This affects the integration layer between the CUDA-Q toolchain/runtime and the external IQM-REST/QPU backend (parsing & mapping of the --iqm-machine option), not the pure build environment or a single backend library. ","This is an implementation error in the handling/transfer of machine names (e.g., splitting at spaces or incorrect comparison); additional compile-time analyses of the user code or stronger typing of the Quantum programs would not prevent this. A fix is needed in the CLI/runtime implementation itself. "
NVIDIA/cuda-quantum,819,https://github.com/NVIDIA/cuda-quantum/issues/819,from_state prepares incorrect state,closed,2023-10-24T03:55:43Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,C,C,,"cudaq.from_state(statevector) prepares the wrong computational basis state for 3+ qubits (e.g., an input statevector for |111? samples as |110?), even though it appears correct for up to 2 qubits. ","The defect is in the from_state state-preparation routine in the high-level API (how it maps the provided statevector into internal initialization logic / qubit ordering), not in user code syntax or build configuration.",This is a library semantic correctness bug in state initialization; it requires fixing the from_state implementation and cannot be prevented by generic compile-time or user-side static checks. 
NVIDIA/cuda-quantum,814,https://github.com/NVIDIA/cuda-quantum/issues/814,Ternary operator not working in `__qpu__` kernels,closed,2023-10-23T20:08:17Z,API-/Usage-/Logic-Bug (High-Level) ,Backend-Library ,B ,B ,B2,"The nvq++ compiler is generating IR that always executes the instructions involved in ternary operations. It should generate conditional IR instead. That is - for the a ? b : c expression, it should evaluate a, and then based on the result of a, it should then evaluate b OR c, not both.",The defect lies in the CUDA-Q C++ frontend / Quake IR lowering for ternary (?:) operators inside kernels: the generated IR encodes the wrong control-flow semantics before any backend simulator or environment is involved,A specialised IR verifier or compiler test generator could detect that a supposed conditional expression has both branches evaluated and merged which requires analysis of the generated control flow rather than simple local type/contract checks
NVIDIA/cuda-quantum,810,https://github.com/NVIDIA/cuda-quantum/issues/810,Logical `&&` operator not working in `__qpu__` kernels,closed,2023-10-23T12:35:57Z,API-/Usage-/Logic-Bug (High-Level) ,Framework-Integration ,C,C,,A kernel that works with a logical && is translated in IR with incorrect short-circuit/branch logic. The compiler violates the semantics of the high-level language. ,"The error lies in IR generation/optimization (front end ? Quake/MLIR ? target IR), i.e., in the compiler/framework integration layer. ","Incorrectly generated branch/logical IR is a typical pass/compiler bug; it cannot be avoided by analyzing the user kernels at compile time, but only by fixing/verifying the transformations. "
NVIDIA/cuda-quantum,806,https://github.com/NVIDIA/cuda-quantum/issues/806,[QIR] Lowering ctrl-swap not implemented,closed,2023-10-20T19:29:49Z,API-/Usage-/Logic-Bug (High-Level) ,Framework-Integration ,C,C,,"The lowering code for two-target operations contains a hard error message for controlled variants, i.e., certain valid operations are simply not supported. A logic/feature gap in the compiler. ","The bug lies in the LowerToQIR/Pass code (Quake/MLIR ? QIR), i.e., in the compiler/framework integration layer. ",The fact that a certain operation is not implemented in lowering is purely an implementation issue; additional compile-time analysis of the user code cannot remedy this. 
NVIDIA/cuda-quantum,805,https://github.com/NVIDIA/cuda-quantum/issues/805,[QIR] Bug in lowering multi-ctrl to LLVM,closed,2023-10-20T18:58:06Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"Lowering a multi-controlled operation (via cudaq::control(...) / x<cudaq::ctrl>) produces incorrect behavior: when the Quake is lowered to LLVM/QIR, executing the program yields a wrong value for the first control qubit in the multi-control invocation","The bug is in the compiler lowering pipeline from Quake/MLIR to LLVM/QIR-specifically how multi-control is represented and passed to the QIR helper (invokeWithControlQubits) / controlled QIS calls during LLVM generation, not in user code or runtime environment",This is a semantic correctness defect in the compiler's QIR/LLVM lowering for multi-control; it requires fixing the lowering/codegen implementation and cannot be prevented by generic user-side compile-time checks or type validation.
NVIDIA/cuda-quantum,799,https://github.com/NVIDIA/cuda-quantum/issues/799,Issue with generated thunk for kernel with cc.callable argument,open,2023-10-19T20:17:13Z,API-/Usage-/Logic-Bug (High-Level) ,Framework-Integration ,C,C,,The generated IR calls via a cc.undef function pointer instead of a correctly set pointer. Llogic bug in the compiler chain. ,"The error occurs in the IR/Codegen integration (front end ? Quake/MLIR ? LLVM/QIR), i.e., in the compiler/framework layer. ",Incorrectly initialized function pointers in the generated IR are an internal compiler problem; this cannot be avoided by user code analysis at compile time. 
NVIDIA/cuda-quantum,776,https://github.com/NVIDIA/cuda-quantum/issues/776,Broadcasting on observe yields incorrect results ,closed,2023-10-16T12:35:16Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,C,C,,"For batched parameters (3�2 theta_vals), observe returns a list of the wrong length (and types), i.e., the high-level API does not adhere to its return contract for batched inputs. ","The error lies in the observe/batching logic of the Python frontend, not in the backend or in the build. ",This is an implementation error in the result aggregation; additional compile-time analyses of the user code do not change this; a fix in the framework is required. 
NVIDIA/cuda-quantum,759,https://github.com/NVIDIA/cuda-quantum/issues/759,Hamiltonian list does not work with observe_async,open,2023-10-11T15:44:08Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,A,A,,"observe_async only supports a single SpinOperator, but breaks down with a list, even though observe works with a list. So inconsistent API/contract logic. ","This only affects the Python frontend or the high-level API signatures of observe vs. observe_async, not the backend. ","With stricter type/overload contracts (e.g., different function names or statically typed parameters), you could enforce at compile time that observe_async only accepts the allowed argument type or generates a clear error early on. "
NVIDIA/cuda-quantum,677,https://github.com/NVIDIA/cuda-quantum/issues/677,[Bug] Cross dependence between regression and unit tests,open,2023-09-20T21:04:00Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment ,C,C,,"A Quake regression test depends on IonQ-specific environment/tests, resulting in fragile, environment-dependent test runs. Configuration design problem. ","It's about test/build infrastructure and its dependencies, not runtime or compiler logic. ","Such cross-dependencies in tests are organizational/infrastructure problems; they cannot be prevented by analyzing user kernels, but only by improving test structuring."
NVIDIA/cuda-quantum,640,https://github.com/NVIDIA/cuda-quantum/issues/640,Async execution in Python is broken,closed,2023-09-11T13:28:34Z,Backend-/Framework-Integrations-Bug ,Runtime-/Framework-Runtime ,C ,C ,,Asynchronous execution uses Python objects in C++ threads without proper GIL handling. Integration problem between Python runtime and C++ async execution. ,"The bug lies in runtime behavior (threads, GIL, async executor), not in compilation or pure backend implementation. ",Race/threading/GIL issues are runtime/implementation details; they cannot be reliably prevented by static analysis of Quantum user code at compile time. 
NVIDIA/cuda-quantum,637,https://github.com/NVIDIA/cuda-quantum/issues/637,Nightly integration test failures for 4 IonQ tests (empty programs),closed,2023-09-10T20:41:53Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,B ,B ,B2,"Combining several changes completely optimizes the program away, and the IonQ backend call fails on an empty program. Problem in the interaction between the optimizer and backend requirements. ","The error lies in the compiler/framework layer, which optimizes IR in such a way that virtually no useful code remains for the IonQ backend. ","A robust optimizer/IR validator could detect before submission that the program is completely empty and issue a warning or error, but this requires additional, non-trivial analysis. "
NVIDIA/cuda-quantum,630,https://github.com/NVIDIA/cuda-quantum/issues/630,Python formatting of tests not enforced in CI,closed,2023-09-08T19:38:11Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment ,C,C,,The CI job for Python formatting is configured so that it does not fail when problems occur and thus does not block violations. An error in build/test configuration. ,"Only affects the CI/build layer (yapf check, exit codes) before anything is compiled or executed. ",This is a configuration/script problem with the CI; compile-time analysis of user code has no effect here; a correct pipeline/job configuration is required. 
NVIDIA/cuda-quantum,609,https://github.com/NVIDIA/cuda-quantum/issues/609,crash in test_runtime_dm,closed,2023-09-06T16:09:04Z,Performance-/Numerik-Bug ,Runtime-/Framework-Runtime ,C,C,,"The Density Matrix Runtime Test returns statistically inconsistent results or fails unexpectedly-this is an error in the algorithmic implementation, not in the API usage. ","The error occurs when executing the runtime/simulator logic (unit tests running, binary starting), not during the build or in the high-level frontend. ","Numerical/runtime bugs in the internal DM implementation cannot realistically be prevented by analyzing the user code at compile time, but only by fixes and tests in the runtime code. "
NVIDIA/cuda-quantum,603,https://github.com/NVIDIA/cuda-quantum/issues/603,Kernel is translated into an invalid QASM,closed,2023-09-05T18:17:38Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,The translator generates QASM with gate names that start with _ (QASM 2.0 incompatible) and with gate definitions that come after their use; this is where the integration between cudaq/Quake-IR and the OpenQASM format fails. ,"It's about the layer where internal kernel MLIR is translated in OpenQASM ""for external consumers"" (QASM backends) a  format/backend integration task, not purely internal high-level API semantics. ","The fact that the generated QASM text violates the specification could be detected by additional QASM linting steps, but these are checks on the generator code, not on the user kernel; in terms of your CTClass definition (analysis of user/kernel code), this is an implementation problem in the translator and thus C. "
NVIDIA/cuda-quantum,583,https://github.com/NVIDIA/cuda-quantum/issues/583,cuda-quantum docker cpu have different result with gpu,closed,2023-08-29T06:19:25Z,Performance-/Numerik-Bug ,Backend-Library ,C,C,,"Without set_target('nvidia'), the VQE run delivers physically plausible energies and a non-trivial state vector, whereas with GPU target it always delivers the same incorrect value and a practically zero state. �� this is a numerical correctness error in the GPU path, not purely an API or config problem. ","The problem only occurs in the nvidia target, i.e., in the GPU backend implementation (cuStateVec/cuTensorNet or their connection); the same high-level code works with the default backend. ","Whether the GPU backend core calculates correctly depends on internal numerical code, FP paths, and, if applicable, hardware details; a static check of user kernels or API contracts cannot prevent a specific backend path from always producing the same incorrect energy and a zero state. "
NVIDIA/cuda-quantum,579,https://github.com/NVIDIA/cuda-quantum/issues/579,Segmentation fault with --emulate option on some programs when saving measurements to variables,closed,2023-08-28T12:47:34Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,B ,B ,B2,"Changing the measurement from mz(qubits) to auto r0 = mz(qubits[0]) ... is semantically harmless, but suddenly leads to a segfault because the framework no longer fills the expected __global__ register-here, the measurement/result semantics of the high-level API breaks its contract. ","The report describes that the LLVM IR hardly changes, but additional registerName attributes and the absence of the __global__ register lead to problems-this is logic in frontend/result handling, such as how measurements in kernel variables and global result registers are merged. ","An IR/ABI validator could check at compile time whether the invariants of the host ABI are satisfied for all permitted measurement patterns (including storage in local variables) – in particular, that the expected __global__ register is set up correctly; this is advanced, but in principle static analysis. "
NVIDIA/cuda-quantum,577,https://github.com/NVIDIA/cuda-quantum/issues/577,Issue with MLIRGen and NVQ++ Linking,open,2023-08-24T17:41:19Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,B ,B ,B2,"Adding additional (even unused) __qpu__ kernel lambdas changes the behavior of the program in such a way that suddenly no counts are returned on the RemoteRESTQPU. This indicates faulty kernel/entry point semantics in the user-facing API/kernel model, not purely environment configuration. ","The bug lies in how the framework determines the ""correct"" entry point for remote execution from the defined kernels/lambdas and wires library mode vs. direct QPU call-this is frontend/framework logic around kernel resolution. ",A sufficiently smart static check of the kernel IR/metadata could detect that multiple candidate entry points are defined or that the kernel marked as the entry point does not match the expected signature/execution mode and refuse compilation instead of running into a “silent failure” mode without counts. 
NVIDIA/cuda-quantum,573,https://github.com/NVIDIA/cuda-quantum/issues/573,ConcatOp Canonicalization,closed,2023-08-22T19:20:03Z,Performance-/Numerik-Bug ,Framework-Integration ,C,C,,"The generated IR is semantically correct, but after multicontrol decomposition and gate set mapping, it contains superfluous quake.concat operations that only affect performance/IR quality (""superfluous and could probably be optimized away""). ","The problem arises in the interaction of various transformation/lowering passes that target specific backend gate sets (e.g., Quantinuum)-i.e., in the integration layer between frontend IR and backend-oriented representation. ","Ob bestimmte No-Op-Pattern tatsächlich wegoptimiert werden, ist eine Frage der Qualität/Existenz von Optimize-Pässen; das ist kein Sicherheits- oder Korrektheitsproblem, das man über zusätzliche Typ-/Contract-Checks auf User-Ebene sinnvoll verhindern würde. "
NVIDIA/cuda-quantum,553,https://github.com/NVIDIA/cuda-quantum/issues/553,Auto-kernel test is failing on ARM,closed,2023-08-13T17:39:23Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The issue describes that exactly one specific test (NVQPP auto-kernel test) fails on aarch64 and was therefore restricted to x86_64 in PR #548 it is not a matter of incorrect user API usage or environment configuration, but rather missing/broken support for this path on one architecture. ","The error manifests itself when executing the nvqpp auto kernel workflow (compiler frontend + backend selection) on a specific platform; this is precisely the integration layer between the framework, compiler, and target architecture, not the pure build/installer. ","Architecture/platform-specific runtime issues (tests run on x86_64 but not on aarch64) depend on binaries, ABIs, and toolchain details that a static check of the user code cannot handle – realistically a C class. "
NVIDIA/cuda-quantum,530,https://github.com/NVIDIA/cuda-quantum/issues/530,Assertion in `vqe_h2.cpp` example with IonQ-emulate target,closed,2023-08-08T13:43:57Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The example vqe_h2.cpp runs in general, but fails with IonQ target in an assertion in array handling („index 4“ at size e 4) - this is an error in the interaction between the cudaq framework and the IonQ-specific backend implementation, not a general API or user error. ","The issue affects the layer in which the framework calls the IonQ backend and passes data structures (shots/results) back and forth; somewhere in this integration logic, incorrect indexing occurs.",The specific off-by-one error occurs in the implementation of the integration/result handling code; a static check of the user kernel (or simple type contracts) cannot reliably prevent someone from using index == size instead of < size internally. 
NVIDIA/cuda-quantum,521,https://github.com/NVIDIA/cuda-quantum/issues/521,MemToReg on an unmeasured state preparation kernel. ,closed,2023-08-03T13:51:22Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,B ,B ,B2,"A valid kernel without measurements is transformed by the value semantics pipeline (including factor-quantum-alloc, memtoreg) in such a way that all operations disappear and only quake.null_wire remains. The API/transformation logic violates its own semantics vis-�-vis the user here. ","The error lies in the transformation/optimization pipeline provided by cudaq for kernel IR (frontend/quake level), not in a specific hardware backend or environment. ","This is caused by an incorrect/unsound IR transformation in the value-semantics optimization pipeline (factor-quantum-alloc / memtoreg) that eliminates valid quantum operations when no measurements are present. It’s not preventable by simple type checks, but could be caught pre-execution by a dedicated IR/pipeline verifier or pass-level regression checks that assert semantic preservation across these transformations "
NVIDIA/cuda-quantum,507,https://github.com/NVIDIA/cuda-quantum/issues/507,nvq++ pass pipeline parser error on hardware,closed,2023-07-27T22:11:44Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The error only occurs in the C++ hardware examples for IonQ/Quantinuum and manifests itself in that the configured pass pipeline contains an unregistered lambda-lifting pass, while other paths (Python examples) work. This is an integration error in the interaction between nvq++/cudaq-opt and the backend configurations. ","This affects the layer where the framework ties together the pass pipeline and backend config and calls cudaq-opt; Build/Environment is OK, but the ""wired"" pipeline for these targets is incorrect. ",Whether a specific pass name is actually available in the pass registry at runtime depends on the build/installation and internal tooling; a compiler that only analyzes the user kernel cannot guarantee this in advance – this is primarily a tool/deployment integration problem. 
NVIDIA/cuda-quantum,487,https://github.com/NVIDIA/cuda-quantum/issues/487,Support typedef for integral and floating-point variables/values,closed,2023-07-25T19:53:07Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,B ,B ,B2,"The issue describes that __qpu__ kernels with ""normal"" standard types as arguments, but the compiler crashes with typedef/alias types and the type aliasing logic is incomplete-this is a bug in the publicly visible kernel/type semantics, not in the environment or backend. ","The bug is in nvq++/frontend, or rather in the way kernel argument types (including aliases) are analyzed and mapped to Quake/MLIR-before any backend or simulator comes into play. ","With better static type/alias analysis in the compiler (e.g., normalized representation of all allowed aliases, validator pass over the IR), this class of type handling bugs could in principle be prevented at compile time; however, this requires more than just simple “arg_type == expected” checks. "
NVIDIA/cuda-quantum,475,https://github.com/NVIDIA/cuda-quantum/issues/475,Quake measurement ops in value semantics mode,closed,2023-07-24T20:17:47Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,B ,B ,B2,"This concerns semantically incorrect behavior when using the kernel/API, e.g., how measurement/execution logic is interpreted or transformed. ","The error lies in the user API and its semantics (kernel/measurement/entry point logic), not in the backend or deployment. ","With sufficiently robust static analysis (e.g., IR Validator, entry point/signature checks), such inconsistent API behavior would in principle be detectable. "
NVIDIA/cuda-quantum,454,https://github.com/NVIDIA/cuda-quantum/issues/454,"Runtime failures result in a non-descriptive ""Abort"" error when using Anaconda shell",open,2023-07-21T10:47:24Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The error occurs when attempting to submit a job to a hardware backend (e.g., remote QPU) because credentials are missing or the submission mechanism responds incorrectly. Error in the integration between the framework and the backend, not in the user API or environment. ","The error lies in the submission/backend interaction, i.e., in the integration path between user code and remote service; not in the high-level API semantics and not in pure runtime (performance/memory). -API and its semantics (kernel/measurement/entry point logic), not in backend or deployment. ",Such submission/authentication errors can hardly be prevented by static compile-time checks of the user kernels. They depend on deployment/backend configuration. 
NVIDIA/cuda-quantum,428,https://github.com/NVIDIA/cuda-quantum/issues/428,"[Base Profile] Bug with two mz with same registerName = """"",closed,2023-07-17T20:47:18Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,Issue concerns faulty backend interaction or incorrect integration between framework and target system. No user logic or environment configuration. ,The error occurs in the layer where the framework selects or controls backend components: the classic integration layer. ,The problem cannot be detected by static analysis of the user code. It is an implementation/integration error. 
NVIDIA/cuda-quantum,426,https://github.com/NVIDIA/cuda-quantum/issues/426,converting to base profile requires updates to __tdg and __sdg functions,closed,2023-07-17T19:04:29Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The QIR functions for adjoint of T and S (named <prefix>__tdg and <prefix>__sdg) are not correct for QIR base profile. In the base profile those names are spelled <prefix>__t__adj and <prefix>__s__adj, resp. Lowering to base profile needs to be updated.","Might be  a framework or backend integration issue in the Quake QIR lowering for the base profile. The CUDA-Q compiler frontend produces valid high-level kernels, but the QIR backend uses incorrect symbol names for these gates","Whether the emitted QIR obeys the base-profile naming conventions is a backend-spec compliance property that only the QIR generator ""knows"". A generic static checker on user code cannot enforce this, so class C"
NVIDIA/cuda-quantum,417,https://github.com/NVIDIA/cuda-quantum/issues/417,Python should be testable without make install,closed,2023-07-16T17:13:50Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment ,C,C,,"Now if you want to test the python bindings from the build directory, you have to run make install in order for the python folder hierarchy to be in the $BUILD/python directory. ",This is a build / deployment pipeline issue in how CMake installs and exposes the Python package layout for testing: the test setup assumes an “installed” package structure rather than using the artifacts already present in the build tree,"Whether the project supports testing Python bindings from the build tree is a property of the build and packaging workflow, not of individual kernels or API usage"
NVIDIA/cuda-quantum,403,https://github.com/NVIDIA/cuda-quantum/issues/403,Submission to IONQ simulator hangs,closed,2023-07-13T17:43:20Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The executable hangs after submitting a job for execution on the IONQ simulator.  Looking at the dashboard on the ionq website all the jobs are marked as failed due to not having permissions, but hanging the process isn't very informative on the other end. ",The error seems in the integration between CUDA-Q IonQ backend client and the remote IonQ cloud service: job status and error codes from IonQ. no permissions,Whether a remote cloud job fails due to permission issues and how that failure is reported is likely a runtime framework 
NVIDIA/cuda-quantum,399,https://github.com/NVIDIA/cuda-quantum/issues/399,exception thrown in cobyla,open,2023-07-12T17:43:59Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,The generated executable terminates with an uncaught exception being thrown. ,"Seems in the interaction between CUDA-Q (COBYLA) and the IonQ backend path in the framework, not in the user kernel itself: the same example is expected to run, but the integration for this target throws at runtime",An optimiser backend combination throws an exception at runtime depends framework behaviour and numerical edge cases. This is not something a static analysis of the kernel or API usage could reliably predict
NVIDIA/cuda-quantum,381,https://github.com/NVIDIA/cuda-quantum/issues/381,Kernels created by cudaq-quake can't be serialized into OpenQASM,closed,2023-07-09T11:44:04Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C ,C ,,"When kernels are serialized into MLIR using cudaq-quake, the resulting MLIR code also contains a function that can't be translated into OpenQASM using cudaq-translate. ","Assumption: the quantum kernel itself is fine, but the translator does not know how to deal with additional  functions in the same module ",Whether the OpenQASM backend supports or skips auxiliary functions is a property of that translation pipeline 
NVIDIA/cuda-quantum,380,https://github.com/NVIDIA/cuda-quantum/issues/380,Kernel calls can't be translated into OpenQASM,closed,2023-07-09T09:06:41Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,Quake code in which a kernel is called by another kernel can't be translated to OpenQASM. ,"Problem seems to be in the framework integration between Quake MLIR and the OpenQASM translation backend.  the C++ kernels and Quake IR are valid and runnable, but the OpenQASM codegen cannot handle kernel-to-kernel calls ",Support for translating func call and generating legal  names is a responsibility of the OpenQASM backend 
NVIDIA/cuda-quantum,379,https://github.com/NVIDIA/cuda-quantum/issues/379,`r1` gate isn't correctly translated to OpenQASM,closed,2023-07-09T08:14:30Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"When translating Quake to OpenQASM, r1 gates are translated to cu1 gates instead of u1 gates. ","Assumption: The defect lies in the Quake OpenQASM translation backend, specifically in the gate mapping table that maps CUDA-Q Quake r1 operation to the wrong OpenQASM primitive",Correctness of this Name semantics mapping is a backend specific codegen concern. Ggeneric static analysis of user kernels cannot detect that the translator chose cu1 instead of u1
NVIDIA/cuda-quantum,378,https://github.com/NVIDIA/cuda-quantum/issues/378,Kernels created by `cudaq::kernel_builder` can't be translated to OpenQASM,closed,2023-07-09T07:55:31Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The issue (continuation of #380) describes that the QASM generator for builder-based kernels fails because, for example, no cudaq-entrypoint attribute is set or is interpreted incorrectly. Seems to be a problem in the backend integration part (MLIR to QASM), not in the user kernel itself. ",The defect lies in the integration between the kernel builder’s to_quake() implementation and the Quake translation to QASM,Whether the QASM translator handles builder kernels and entry point attributes correctly depends on its implementation; additional analysis of the user kernel cannot ensure that the tool chain produces valid QASM output – hence CTClass C. 
NVIDIA/cuda-quantum,349,https://github.com/NVIDIA/cuda-quantum/issues/349,IR produced when compiling for Quantinuum and IonQ backends is not spec compliant,closed,2023-07-05T12:45:03Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,B ,B ,B2,"The issue explicitly states that the names of the QIR functions for T- and S-adjoint (__tdg, __sdg) do not comply with the QIR Base Profile and must be changed to __t__adj/__s__adj � This is a misalignment between CUDA-Q's QIR emitter and the formal QIR specification. ","We are right in the layer where CUDA-Q casts its internal representation into QIR Base Profile so that other tools can interpret it-in other words, a format/backend integration task. ","QIR Base Profile is formally specified; a QIR validator (e.g., in the style of QAT) could check at compile time whether all function names and signatures are compatible and comply with the Base Profile rules. This is advanced IR analysis and therefore CTClass B. "
NVIDIA/cuda-quantum,345,https://github.com/NVIDIA/cuda-quantum/issues/345,Error when trying to simulate `qspan`,closed,2023-07-03T19:57:10Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The issue shows that interaction with a specific simulator/backend (e.g., qpp) leads to crashes/malfunctions. Not because the algorithm is numerically unstable, but because the integration (control/target dimensions, mapping, etc.) is not implemented correctly. ","The cause is the way the framework prepares the qpp backend call (e.g., incorrect layout, incorrect parameters, incorrect control/target assignment), i.e., a clear integration layer between the high-level kernel and the backend. ",A static check at the user kernel level cannot ensure that the internal qpp call does not contain any off-by-one/dimensioning errors in the implementation; this is implementation work in the integration code so C. 
NVIDIA/cuda-quantum,344,https://github.com/NVIDIA/cuda-quantum/issues/344,Compiler crash when compiling a kernel with `std::uint8_t` as argument,closed,2023-07-03T19:52:03Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,B ,B ,B2,"Users employ certain legal C++ types or signatures for __qpu__ kernels, causing the compiler/bridge to crash or generate incorrect IR-this is a logic error in the high-level interface (type/signature handling), not a backend or build problem. ","How kernel argument types are analyzed and translated into IR is clearly the task of the high-level front end; the bug is located there (e.g., in type inference, function signature handling), not in the underlying back end or an external library. ","With a more robust type/signature validator for kernel definitions (which ensures that only supported types occur in permissible combinations and that all branches of the type dispatch are covered), such errors could in principle be detected/prevented at compile time; however, this requires advanced compiler analysis and clear type rules, so B. "
NVIDIA/cuda-quantum,343,https://github.com/NVIDIA/cuda-quantum/issues/343,Unable to unroll a counted loop,closed,2023-07-03T19:41:01Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The issue describes faulty behavior/crash in conjunction with a specific backend/target (not purely a ""slow"" or numerically inaccurate path), but rather that something breaks in the framework-backend path-typical for 1.3. ","The cause lies in the wiring of CUDA-Q mechanisms to a specific backend (e.g., IonQ/Quantinuum/QIR paths), not in the high-level API design or build system itself. ","Diese Art Integrations-/Crash-Fehler entsteht aus den internen Details der Aufrufkette und der Backend-Implementierung; ein Compile-Time-Check auf Basis von User-Kernel-IR kann nicht sicherstellen, dass der richtige Backend-Call mit korrekten Parametern implementiert ist. "
NVIDIA/cuda-quantum,341,https://github.com/NVIDIA/cuda-quantum/issues/341,Linker error when trying to build kernel with `std::acos`,closed,2023-07-03T17:13:10Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The issue here is that certain standard math functions (acos, etc.) are not correctly linked to the target environment in the resulting QIR/backend profile (e.g., incorrect name or missing mapping) . this is an error in the interaction between the compiler/QIR and the runtime/math library. ","This affects the layer that maps QIR/IR functions to specific runtime functions on the target platform; it is not a build/install issue, nor is it purely high-level API semantics, but rather the integration of the backend profile and the actual runtime environment. ","Whether a linker/runtime symbol is correctly linked depends on the toolchain, symbol name, and runtime layout. A static check of the user kernel cannot reliably prevent this in practice; this means that the CTClass C. "
NVIDIA/cuda-quantum,339,https://github.com/NVIDIA/cuda-quantum/issues/339,Failure to create `qreg` using kernel argument as size,closed,2023-07-03T16:16:40Z,API-/Usage-/Logic-Bug (High-Level) ,Backend-Library ,A ,A ,,We seem to be getting a failure when trying to allocate a qreg that has a size defined by an argument: ,"This is a defect in the CUDA-Q library that lowers kernels and implements qreg construction, not in the users host code or environment, hence it sits in the Backend-Library layer.","A straightforward compiletime contract or type check on the qreg constructor could have caught this mismatch early, so we classify as A"
NVIDIA/cuda-quantum,338,https://github.com/NVIDIA/cuda-quantum/issues/338,Handle func::ConstantOp for adjoint / control in the ASTBridge,closed,2023-07-03T16:05:47Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,C,C,,"The issue shows that using a free __qpu__ function as a function pointer in cudaq::adjoint() currently leads to a compiler error and special type checks must be retrofitted in ConvertExpr.cpp-the user is making semantically legitimate API usage, but the high-level logic does not support this case. ","The proposed solution directly affects the frontend/type checking code (ConvertExpr.cpp) in the CUDA-Q compiler: a branch for FunctionType is missing, i.e., high-level API/compiler frontend logic, not backend. ","The fact that this specific functional case is not handled in the implementation of the front end is an internal compiler bug; a separate compile-time analysis step that inspects the user code cannot prevent this “preventively” – the correction is in the compiler itself, not through additional constraints on the kernel. "
NVIDIA/cuda-quantum,337,https://github.com/NVIDIA/cuda-quantum/issues/337,Disappearing instructions.,closed,2023-07-03T15:43:02Z,API-/Usage-/Logic-Bug (High-Level) ,Framework-Integration ,C,C,,"The behavior is a semantic error in the visible behavior of the CUDA-Q API or in the interaction of the high-level functionality called by the user, not primarily a pure performance/numerical error-the issue describes ""incorrect"" or inconsistent logic. ","The cause lies in the interaction between the high-level front end and underlying components/targets (e.g., certain targets or execution paths react differently than expected); in other words, the integration level, not just front-end internal syntax/parsing. ",The specific error situation results from the implementation of the framework integration path; there is no simple or even advanced check on the user kernel that would deterministically detect this type of integration logic error in advance. 
NVIDIA/cuda-quantum,327,https://github.com/NVIDIA/cuda-quantum/issues/327,Makefiles are missing dependencies,closed,2023-06-29T22:24:05Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment ,C,C,,"The issue describes that in order to test the Python bindings from the build directory, you first have to run make install, because otherwise the Python hierarchy is not in the expected location. this is a install/packaging/CMake logic bug. ","This affects how the project is built and installed (build dir vs. install dir, Python path structure), not runtime interaction with a quantum backend or API semantics. ",Such build/installation path issues cannot be prevented by analyzing __qpu__ kernels or API calls; they depend on CMake/packaging decisions and file system layout → clearly CTClass C. 
NVIDIA/cuda-quantum,325,https://github.com/NVIDIA/cuda-quantum/issues/325,Calling a kernel via an instance creates an incorrect allocation,closed,2023-06-29T18:02:09Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,C,C,,"The example shows two __qpu__ kernels (S1, S2) where the bridge/frontend generates an incorrect cc.alloca IR from formally correct C++/CUDA Q code-this is a logic error in the high-level kernel/IR generation behavior, not a build or backend implementation problem. ","The error lies directly in the translation of C++ kernel structures (function objects, calling S2 in S1) in Quake/MLIR; here, the high-level front-end logic is working incorrectly before any concrete backend comes into play. ","Whether the bridge generates a “malformed cc.alloca” depends on internal implementation logic in the compiler; this cannot be reliably prevented by additional type or contract checks on the user kernel side. You need robust implementation tests, not CT analyses of the user code. "
NVIDIA/cuda-quantum,296,https://github.com/NVIDIA/cuda-quantum/issues/296,Failing to compile `if` statements to quantinuum target,closed,2023-06-26T13:43:09Z,API-/Usage-/Logic-Bug (High-Level) ,Backend-Library ,C,C,,"When targeting quantinuum, the compiler seems to fail lowering if statements. ",The crash happens during backend lowering qnd JIT compilation for the Quantinuum target,This is an internal compiler and JIT bug for a specific backend. A static analysis of user kernels cannot predict or prevent an LLVM assertion 
NVIDIA/cuda-quantum,291,https://github.com/NVIDIA/cuda-quantum/issues/291,[pass] Multicontrol decomposition erases non-multi control ops,closed,2023-06-26T09:09:14Z,Performance-/Numerik-Bug,Framework-Integration ,C,C,,"A decomposition/optimization pass for ""multi control"" also incorrectly deletes other operations, thereby changing the program semantics. Error in the transformation/optimization pass logic. ","The bug is located in the IR transformation backend (MLIR/compiler passes) in the CUDA-Q stack, i.e., once again in the compiler/framework integration layer, not in the high-level API or deployment. in the translation of C++ kernel structures (function objects, calling S2 in S1) in Quake/MLIR; here, the high-level frontend logic is working incorrectly before any concrete backend comes into play. ",The bug lies in the implementation of the pass itself (incorrect rewrite rules); static analysis of the user code cannot predict that the compiler internally transforms incorrectly and removes ops so C. 
NVIDIA/cuda-quantum,281,https://github.com/NVIDIA/cuda-quantum/issues/281,Canonicalization of extract_ref doesn't fold constants with index type,closed,2023-06-22T19:45:14Z,Performance-/Numerik-Bug,Framework-Integration ,C,C,,"A canonicalization/optimization pass is missing or not working in the IR pipeline context, so that unnecessarily ""worse""/unoptimized code remains. This is an optimization/performance problem. ","The cause lies in the composition/integration of the compiler pipeline (which passes run when), i.e., in the IR/framework integration layer, not in the build system. ",Whether certain canonicalization/optimization passes are included in the pipeline and function correctly is purely an implementation detail of the compiler; the user kernel is independent of this and offers no leverage for static avoidance so C. 
NVIDIA/cuda-quantum,276,https://github.com/NVIDIA/cuda-quantum/issues/276,Platform config files cannot handle passes with options,closed,2023-06-22T09:14:55Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The pipeline configuration for lowering/optimization passes is disrupted by overly simplistic string splitting logic (split on '='), because pass options themselves contain =. This is an integration/configuration parsing bug in the runtime support layer. ","It's about integrating the text configuration (PLATFORM_LOWERING_CONFIG) with the pass pipeline in the runtime/backend wrapper, i.e., clearly framework integration and not purely build environment. ","The error is in the parser for configuration strings; neither types nor static analysis of the user kernel can prevent someone from implementing such a naive string operation, so C. "
NVIDIA/cuda-quantum,258,https://github.com/NVIDIA/cuda-quantum/issues/258,Driver wrongly reporting argument as ignored,closed,2023-06-14T08:59:36Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,C,C,,"The nvq++ driver incorrectly reports --quantinuum-url as ""ignored,"" even though the argument is actually used by the target configuration script page. Faulty user-facing logic/error message. ","This affects the CLI/driver layer (nvq++) as part of the high-level API, not the backend itself or the build environment. ",Whether a specific CLI argument is actually used internally or whether the warning is correctly formulated is purely a question of implementation in the tool; this has no relation to the user kernel and cannot be detected by type/IR analysis. 
NVIDIA/cuda-quantum,252,https://github.com/NVIDIA/cuda-quantum/issues/252,A job should not be posted if we failed JIT compilation ,closed,2023-06-13T15:38:36Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"Despite a JIT error (""could not trace offset value""), a job is still sent to the Quantinuum backend mock. Error handling/integration problem between JIT and job submission. ","It involves transferring ""JIT successful/failed"" to the remote backend client and its job submission, i.e., the integration between compiler runtime and remote service. ","Whether the JIT error is correctly intercepted and a job is suppressed depends solely on the implementation of the runtime/submission logic; the user kernel is syntactically/semantically correct, so there is no meaningful compile-time prevention. "
NVIDIA/cuda-quantum,251,https://github.com/NVIDIA/cuda-quantum/issues/251,Lowering single qubit allocations to base profile,closed,2023-06-13T15:29:39Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The base profile lowering pipeline aborts with a kernel with single qubit allocation with ""could not trace offset value"" - this is an error in the interaction between CUDA-Q lowering and base profile/QIR, not in the user code. ","This affects the integration of high-level IR (MLIR/Quake) with the base profile/Quantinuum lowering layer, i.e., the compiler/framework integration layer. ","Whether the lowering code can handle certain IR patterns (single-qubit allocation, certain layouts) correctly is a question of pass implementation; this cannot be reliably determined by additional type or contract checks on the user kernel. "
NVIDIA/cuda-quantum,250,https://github.com/NVIDIA/cuda-quantum/issues/250,Free function kernel compilation in MLIR compilation mode,closed,2023-06-13T15:24:32Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The ""multiple definition of super"" error occurs because the toolchain incorrectly links the same kernel symbol name from different artifacts. Atoolchain bug, not a pure config fail. ","It's about the integration between the nvq++ front end, generated QIR/object code, and the linker for the Quantinuum target. In other words, the framework/toolchain integration layer. ",Not reasonably avoidable at compile time 
NVIDIA/cuda-quantum,179,https://github.com/NVIDIA/cuda-quantum/issues/179,Fix bugs in lowering to base profile [was: Counted loops from the ASTBridge],closed,2023-05-19T14:24:45Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,B ,B ,B2,"The compiler does not recognize template-based loops with a constant bound (N - 1) as ""counted loops""- This is a gap in the high-level compiler logic/loop detection, not an environment or backend problem. ","This affects the CUDA-Q front end (AST bridge/early MLIR passes), which should correctly map C++ template semantics in Quantum loops-i.e., the high-level API/compiler logic layer. ","With appropriate static analysis (constant folding for template parameters, loop/control flow analysis), such loops can be recognized as “counted” at compile time; this is not trivial (not a simple type check), but theoretically feasible. "
NVIDIA/cuda-quantum,177,https://github.com/NVIDIA/cuda-quantum/issues/177,CI error after merge ,closed,2023-05-18T11:30:53Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment ,C,C,,"The problem occurs when building the Docker/Dev environment (missing/incorrect base_image/build args, cache behavior), so it is a build or packaging error. ","This concerns Docker builds and image configuration, i.e., deployment/environment issues, and not the running CUDA-Q or backend logic. ",Whether a Docker build arg is set and which base images are available cannot be checked by analyzing the CUDA-Q user code; this is purely a build/CI setup. 
NVIDIA/cuda-quantum,174,https://github.com/NVIDIA/cuda-quantum/issues/174,Bug in QuakeObserveAnsatz Pass for GCC 11.3,closed,2023-05-17T19:33:52Z,Backend-/Framework-Integrations-Bug ,Framework-Integration ,C,C,,"The crash occurs in the observe approach/compiler pass itself (e.g., null context during reification), i.e., in the internal integration of the analysis/transformation pipeline, not due to incorrect use of the API by the user. ","This affects the interaction between the CUDA-Q front end, MLIR passes, and internal observe/approach handling-in other words, the compiler/framework integration layer, not the backend or build environment. ","The problem is an implementation/null check error in the pass itself; static analysis of the user kernel does not help here, so there is no meaningful compile-time protection via types/contracts C. "
NVIDIA/cuda-quantum,149,https://github.com/NVIDIA/cuda-quantum/issues/149,Fix Compiler Warning in QubitQIRExecutionManager,closed,2023-05-10T12:38:35Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment ,A,A,,"The reported defect manifests itself as a compiler warning (-Woverloaded-virtual) during compilation. The build process is ""unclean,"" even though the program runs, indicating a build/code quality issue. ","The effect occurs when translating the runtime classes (BasicExecutionManager vs. QIRExecutionManager) and therefore belongs to the build/toolchain layer, not to the actual runtime or API layer. ","The compiler already recognizes the problem today (warning with exact source location); with appropriate warning policies or CI rules, this error could be strictly prevented at compile time. "
NVIDIA/cuda-quantum,83,https://github.com/NVIDIA/cuda-quantum/issues/83,Build issues with cuQuantum SDK v23.03 installed via Ubuntu apt-get,closed,2023-04-13T03:20:17Z,Build-/Install-/Packaging-Bug,Build/Deploy/Environment ,B ,B ,B1,"When installing cuquantum via apt-get (e.g., sudo apt-get -y install cuquantum) as described here, with the latest cuQuantum SDK v23.03, the install location is different from the previous version: ",This is a build / deployment integration problem between CUDA-Q CMake scripts and the cuQuantum SDK packaging ,"Eine CMake-Prüfung während der Konfiguration mit find_library über Standard-Systembibliotheksverzeichnisse (wie im Ticket vorgeschlagen) könnte das neue cuQuantum-Layout zuverlässig erkennen und mit einem Hinweis schnell fehlschlagen, wodurch dies zu einer Umgebung wird. "
NVIDIA/cuda-quantum,69,https://github.com/NVIDIA/cuda-quantum/issues/69,Bug with getting expected value from observe_result with no shots provided,closed,2023-04-05T14:30:21Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,C,C,,The interaction between cudaq.observe(...) + result.expectation_z(cudaq.spin.z(1)) only responds correctly if shots_count is explicitly set; the default semantics are inconsistent with user expectations and the API documentation ? high-level logic bug. ,"The error lies in the result processing and statistics logic of the Python API, not in a specific backend or the build environment. ",Whether default parameters and evaluation methods deliver the “correct” physical quantity depends on the specific implementation of the statistics and sampling logic—this cannot be prevented in a meaningful way by static analysis of the user kernel. 
NVIDIA/cuda-quantum,64,https://github.com/NVIDIA/cuda-quantum/issues/64,Seg fault after printing the circuit in python ,closed,2023-04-04T20:47:21Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,C,C,,"A semantically legal pattern (x-gate, print(circuit), followed by another gate) leads to a segfault. This is an error in the internal representation/mutation logic of the high-level circuit API, not just ""slowness"" or numerics. ",This affects the Python kernel representation of CUDA-Q and its print implementation; the problem arises before any simulator/backend is addressed. ,The fact that print confuses internal pointers/state to such an extent that the next gate call crashes is an implementation error in the API; additional static checks on the user code cannot prevent this runtime state corruption bug. 
NVIDIA/cuda-quantum,49,https://github.com/NVIDIA/cuda-quantum/issues/49,ExecutionManager Needs Updates for Handling Qudits,closed,2023-04-03T14:24:12Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,C,C,,"The issue requires refactoring the ExecutionManager and associated API so that they correctly support qudits (more than 2 levels); currently, the interface is designed specifically for qubits. This is an API or design issue. ","It concerns the abstract ExecutionManager API and its signatures (QuditInfo, returnQudit, etc.), i.e., precisely the high-level framework/language specification layer. ","Whether the API design is qudit-capable depends on the chosen interface; an analysis of the user code cannot “force” the library to implement a different, more general interface. It is not a CT avoidability case in the sense of your decision tree. "
NVIDIA/cuda-quantum,28,https://github.com/NVIDIA/cuda-quantum/issues/28,Incorrect list of QPUs returned from query of runtime,closed,2023-03-24T12:54:49Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,C,C,,"cudaq.list_qpus() lists 'custatevec', although the correct name according to the rest of the stack is cuquantum – this is an incorrect entry in a user-facing API. ","The function is part of the high-level frontend and its static backend registry; the error lies in this API list, not in the lower backend layer. ","Even if you can build internal tests/checks, this is not a problem in terms of your CT concept that can be intercepted by additional analysis of the user kernel. It is a hard implementation/constant error in the framework. "
NVIDIA/cuda-quantum,27,https://github.com/NVIDIA/cuda-quantum/issues/27,RuntimeError for MGMN backend,closed,2023-03-24T10:38:09Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,C,C,,"The documentation refers to a backend name cuquantum_mgmn, which cudaq.set_qpu('cuquantum_mgmn') then rejects as ""Invalid qpu name"". Inconsistent high-level API/documentation behavior, not a backend or build issue. ",This affects the QPU selection API and its registry of valid backend strings; this takes place entirely in the high-level framework. ,"The error is an internal data/documentation bug in the framework; an analysis of the user code (e.g., string literals) is not sufficient to ensure at compile time that documentation, registry, and implementation are kept consistent. This is ultimately a matter of maintenance/implementation discipline, not CT analysis. "
NVIDIA/cuda-quantum,3,https://github.com/NVIDIA/cuda-quantum/issues/3,Fix bug with mid-circuit measurement to a named register,closed,2023-03-20T19:15:47Z,API-/Usage-/Logic-Bug (High-Level) ,High-Level-API / Framework-Logic ,C,C,,"The user calls kernel.mz(qreg, register_name=""test_measurement"") and expects measure_counts.register_names() to contain this name; however, the feature has not (yet) been implemented in CircuitSimulator - the API contract is broken. ","The problem lies in the behavior of the high-level simulator and the sampling result API (register name handling), not in backend libraries or build/environment issues. ",Whether a keyword argument such as register_name is actually supported and correctly transferred to the result object is a matter of internal implementation and testing; this cannot be guaranteed by additional compile-time analysis of the user code. 
